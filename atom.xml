<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://www.plbear.com</id>
    <title>Plbear | Cuz Penguin QQ</title>
    <updated>2019-08-01T14:26:43.829Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://www.plbear.com"/>
    <link rel="self" href="https://www.plbear.com/atom.xml"/>
    <subtitle>Food And Freedom. Make my own world a better place.</subtitle>
    <logo>https://www.plbear.com/images/avatar.png</logo>
    <icon>https://www.plbear.com/favicon.ico</icon>
    <rights>All rights reserved 2019, Plbear | Cuz Penguin QQ</rights>
    <entry>
        <title type="html"><![CDATA[运维的生活中常见的Nginx规则]]></title>
        <id>https://www.plbear.com/post/nginx-rule</id>
        <link href="https://www.plbear.com/post/nginx-rule">
        </link>
        <updated>2019-08-01T14:24:47.000Z</updated>
        <content type="html"><![CDATA[<div><h1><strong>1. 概述</strong></h1><p>大家都知道Nginx有很多功能模块，比如反向代理、缓存等，这篇文章总结下我们这些年实际环境中那些有用的Nginx规则和模块，大部分是用法的概括及介绍，具体细节在实际配置时再自行google。</p><h1><strong>2. 内置语法</strong></h1><p>先介绍Nginx默认已支持的内置功能，靠这些基本就满足大部分的web服务需求。</p><h1><strong>2.1 proxy代理</strong></h1><p>proxy常用于两类应用场景，一类是中转，如异地科学的上网方式，另外一类是到后端服务的负载均衡方案。</p><p>用反向代理时候，需要特别注意里面的域名默认是在nginx启动时候就解析了，除非reload否则一直用的是当初解析的域名，也就是说不能动态解析。</p><p>但这个问题是可以通过别的模块或者用内置字典变量方式来解决。</p><pre>resolver 114.114.114.114;<br>server {<br> location / {<br> set $servers github.com;<br> proxy_pass http://$servers;<br> }<br>}<br></pre><h1><strong>2.1.1 中转</strong></h1><p>针对某个域名进行中转：</p><pre>server {<br>listen 172.16.10.1:80;<br> server_name pypi.python.org;<br> location ~ /simple {<br> proxy_set_header Host $http_host;<br> proxy_redirect off;<br> proxy_pass http://pypi.python.org;<br> }<br>}<br></pre><p>注意如果是前后端域名不一样的话需要处理proxy_redirect的301跳转之类的显示，否则在跳转时候会跳转到proxy_pass的域名。</p><p>另外可以直接代理所有80端口的http流量：</p><pre>server {<br> listen 80;<br> server_name _;<br> resolver 114.114.114.114;<br> set $URL $host;<br> location / {<br> proxy_pass http://$URL;<br> }<br>}<br></pre><p>如果是想代理https的站点也不是不可能，只是需要自行处理CA证书导入即可，而且经过https中转的流量对nginx是透明的，也就是有证书的时候做窃听和劫持的情况。</p><h1><strong>2.1.2 负载均衡</strong></h1><p>这是代理的另外一个常见用法，通过upstream到多个后端，可以通过weight来调节权重或者backup关键词来指定备份用的后端，通常默认就可以 了，或者可以指定类似ip_hash这样的方式来均衡，配置很简单，先在http区域添加upstream定义：</p><pre>upstream backend {<br> ip_hash;<br> server backend1.example.com weight=5;<br> server backend2.example.com weight=5;;<br>}<br></pre><p>然后在server里面添加proxy_pass：</p><pre>location / {<br> proxy_pass http://backend;<br> proxy_http_version 1.1;<br> proxy_set_header Connection "";<br>}<br></pre><p>做负载均衡的时候可以智能识别后端服务器状态，虽然可以智能地proxy_next_upstream到另外的后端，但还是会定期损失一些正常的“尝试性”的连接，比如过了max_fails 次尝试之后，休息fail_timeout时间，过了这个时间之后又会去尝试，这个时候可以使用第三方的upstream_check模块来在后台定期地自动探索，类似这样：</p><pre>check interval=3000 rise=2 fall=5 timeout=2000 type=http;<br></pre><p>这样替代用户正常的连接来进行尝试的方式进一步保障了高可用的特性。</p><p>还有就是在做前端代理的时候也是这样的方式，直接proxy_pass到后端即可，比如CDN的场景。</p><h1><strong>2.2 防盗链</strong></h1><p>普通的防盗链是通过referer来做，比如：</p><pre>location ~* \.(gif|jpg|png|bmp)$ {<br> valid_referers none blocked *.example.com server_names ~\.google\. ~\.baidu\.;<br> if ($invalid_referer) {<br> return 403;<br> }<br>}<br></pre><p>再精细一点的就是URL加密，针对一些用户IP之类的变量生成一个加密URL通常是针对文件下载时候用到，可以通过openresty来写lua脚本或者是accesskey之类的模块来实现。</p><h1><strong>2.3 变量</strong></h1><p>nginx里面支持正则匹配和变量配置，默认的变量比如remote_addr、request_filename、query_string、server_name之类的，这些组合在一起可以做很多规则，或者还有日志里面status、http_cookie等。</p><p>还有在进行多域名配置时候可以用通配符，比如：</p><pre>server_name ~^(www\.)?(.+)$;<br>root /data/web/$2;<br></pre><p>这样就实现了自动进行域名的目录指派。</p><p>变量方面，比如配置变量a=1：</p><pre>set $a 1;<br></pre><p>下面这个案例配合if判断来做有更大的用处。</p><h1><strong>2.4 if判断</strong></h1><p>nginx里面支持一些简单的if判断，但是没有多重逻辑的语法，多个判断条件用起来需要结合变量的方式来实现，比如允许ip地址为10.10.61段和和192.168.100段的用户访问，其余的拒绝，返回405状态码：</p><pre>set $err 0;<br> if ( $remote_addr ~ 10.10.61.){<br> set $err 0;<br> }<br> if ( $remote_addr ~ 192.168.100.){<br> set $err 0;<br> }<br> if ( $err = 1){<br> return 405;<br> }<br></pre><p>这样通过一个err变量比较巧妙实现了需求。</p><h1><strong>2.5 error_page</strong></h1><p>有用到后端proxy的地方需要加上这句话才可以传到状态码到nginx：</p><pre>fastcgi_intercept_errors on;<br></pre><p>具体配置一般是配置到具体的错误URL页面，比如：</p><pre>#返回具体状态码<br>error_page 404 403 /4xx.html<br>#返回200状态码<br>error_page 404 403 =200 /error.html<br></pre><p>或者采用callback的方式统一做处理：</p><pre>error_page 404 403 = @fallback; <br>location @fallback {<br> proxy_pass http://backend;<br> access_log /data/logs/404_error.log access;<br>}<br></pre><p>这样在重定向时不会改变URL，然后把404页面直接返回。</p><h1><strong>2.6 rewrite</strong></h1><p>rewrite做一些301、302之类的跳转，同时也可以在CDN前端做“去问号”缓存的效果。</p><pre>location /db.txt {<br> rewrite (.*) $1? break;<br> include proxy.conf;<br>}<br></pre><p>另外最常见的跳转写法：</p><pre>rewrite ^/game/(.*) /$1;<br></pre><p>把/game/test跳转为/test的效果，注意这样是没有状态码的，如果访问正常就直接返回200状态码。</p><p>可以在后面加个permanent参数，就变为了301 Moved Permanently，或者添加redirect改为302跳转。</p><p>同理，还可以进行多个正则匹配进行URL重组，比如：</p><pre>rewrite ^/download/(.*)/lastest/(.*)$ /file/$1?ver=$2 break;<br></pre><h1><strong>2.7 日志字段</strong></h1><p>想针对每个连接进行日志留档，可以在nginx日志那里配置好字段，比如记录cookie之类的数据。</p><p>在log_format字段里面加入$http_cookie变量即可。</p><p>另外post的数据可以永久保留在文件里面，比如用来做http的日志备份，包括get和post的原始数据，把这个值开启即可：</p><pre>client_body_in_file_only on;<br></pre><p>然后post的数据就会保存在nginx/client_body_temp文件夹里面。</p><h1><strong>2.8 internal关键词</strong></h1><p>这个关键词很少见，但有时候是很有用的，比如在有很多规则时候，突然需要针对某个目录转为nginx内部处理。</p><pre>location ^~ /upload/down/ {<br>alias /data/web/dts/dtsfile/down/;<br>internal;<br>}<br></pre><h1><strong>2.9 try_files</strong></h1><p>字面意思是尝试，后面可以接多个目录或者文件，比如kohana框架：</p><pre>try_files $uri /index.php?$query_string;<br></pre><p>先看是否有URL这个文件，没有的话再调用index.php来处理，或者支持状态码处理：</p><pre>try_files /foo /bar/ =404;<br></pre><p>没有这两个文件的话返回404状态。</p><h1><strong>2.10 auth认证</strong></h1><p>可以做简单的用户登录认证方式，其中的passwd_file得通过apache的htpasswd命令来生成。</p><pre>auth_basic "Restricted";<br>auth_basic_user_file passwd_file;<br></pre><p>认证通过之后每次访问会在头部添加Authorization字段包含用户名密码的base64加密密文给服务端。</p><h1><strong>2.11 gzip</strong></h1><p>普通的线上web站点gzip压缩是必须要开的，压缩一些文本类型的文件再返回给用户。</p><p>注意必须手动指定全需要压缩的类型，比如css、js之类的，线上配置如下：</p><pre>gzip on;<br>gzip_min_length 2048;<br>gzip_buffers 4 16k;<br>gzip_vary on;<br>gzip_http_version 1.1;<br>gzip_types text/plain text/css text/xml application/xml application/javascript application/x-javascript ;<br></pre><h1><strong>2.12 mime配置</strong></h1><p>很久以前基本是忽略这个配置，但手游流行之后就发现异常了，需要让手机浏览器知道返回的apk后缀是什么类型，否则类似IE浏览器会以zip后缀返回，需要加上：</p><pre>application/vnd.android.package-archive apk;<br>application/iphone pxl ipa;<br></pre><h1><strong>2.13 限速</strong></h1><p>限速包括限制请求的并发数和请求的下载速度。</p><p>简单的限制某个线程的下载速度就直接加上一句话就可以了：</p><pre>limit_rate 1024k;<br></pre><p>要限制某个IP的并发数之类的就需要用ngx_http_limit_req_module和ngx_http_limit_conn_module模块了，不过是默认就编译好的。</p><p>比如使用一个 10M 大小的状态缓存区，针对每个IP每秒只接受20次的请求：</p><pre>limit_req_zone $binary_remote_addr zone=NAME:10m rate=20r/s;<br></pre><h1><strong>2.14 location匹配</strong></h1><p>location匹配有多种方式，常见的比如</p><pre>location = / <br>location / <br>location ^~ /test{<br></pre><p>是有优先级的，直接 ”=” 的优先级是最高的，一般就用”~”这个符号来匹配php就好了，不过是区分了大小写的：</p><pre>location ~ .*\.php$<br></pre><h1><strong>2.15 文件缓存</strong></h1><p>返回给用户的文件一般都配置了过期时间，让浏览器缓存起来。</p><p>比如缓存14天：</p><pre>expires 14d;<br></pre><p>针对某些特殊的文件就需要location匹配之后进行禁止缓存配置：</p><pre>add_header Cache-Control no-cache;<br>add_header Cache-Control no-store;<br>expires off;<br></pre><h1><strong>2.16 缓存文件</strong></h1><p>nginx可以作为ATS这样的缓存服务器来缓存文件，配置也比较简单，不过我们很少用，除非一些特殊的场合，参考配置：</p><pre>#先在全局下面定义好缓存存放的目录<br>proxy_cache_path /data/cache/ levels=1:2 keys_zone=cache_one:10m inactive=7d max_size=10g;<br>proxy_temp_path /data/cache/proxy_temp_path;<br>proxy_cache_key $host$uri$is_args$args;<br>#然后在server里面的location匹配好目的文件，加入下一段即可<br>proxy_cache cache_one;<br>proxy_cache_valid 200 304 24h;<br>proxy_cache_valid any 10m;<br>proxy_pass https://$host;<br>proxy_cache_key $host$uri$is_args$args;<br>add_header Nginx-Cache "$upstream_cache_status"; 3. 内置模块<br></pre><h1><strong>3. 内置模块</strong></h1><p>nginx含有大量的模块可以支持多种复杂的需求，比如源码目录src/http/modules里面就有很多c模块的代码，或者直接通过./configure –help|grep module来查看有哪些内置模块，编译时候直接加上就可以了。</p><p>除了nginx内置的模块，网络上还有很多第三方的模块，可以通过编译时候加参数–add-module=PATH指定模块源码来编译。</p><p>下面介绍一些我们线上用过而且比较赞的内置模块。</p><h1><strong>3.1 stream</strong></h1><p>端口转发的模块，从nginx1.9版本才开始支持，包含tcp和udp的支持，和IPTABLES相比这个虽然是应用层，会监听端口，但是配置起来很方便，比IPTABLES灵活，在tcp模块下面添加类似vhost的server就可以了，方便自动化管理，参考配置：</p><pre>server {<br> listen PORT;<br> proxy_pass IP:PORT;<br> access_log /data/logs/tcp/PORT.log;<br>}<br></pre><h1><strong>3.2 http_realip_module</strong></h1><p>nginx反向代理之后，如何让后端web直接获取到的IP不是反向代理的iP，而是直接获取到用户的真实IP呢，就需要这个模块了，不需要代码那里再做类似X-Real-IP的变量特殊判断。</p><h1><strong>3.3 http_slice_module</strong></h1><p>在做CDN时候可以用到，让一个大文件分片，分成多个小文件通过206断点续传到后端，然后再组合起来，避免大文件直接回源导致多副本和多次回源的问题。</p><h1><strong>3.4 http_secure_link_module</strong></h1><p>前面说到的防盗链可以用这个来做，但是这个一般是针对那种文件下载时候用到的，比如从网页下载时候，服务端生成一个加密URL给用户，然后这个URL有过期时间之类的，避免此URL被多次分享出去，不过普通的素材加载还是用普通的防盗链即可。</p><h1><strong>3.5 http_sub_module</strong></h1><p>替换响应给用户的内容，相对于sed之后再返回，比如可以在需要临时全局修改网站背景或者title时候可以一次性处理好。</p><h1><strong>4. 扩展项目</strong></h1><p>简单介绍下大名鼎鼎的两个基于nginx的扩展项目，也是我们线上有很多地方用到的。</p><h1><strong>4.1 openresty</strong></h1><p>集成lua脚本，几乎可以完成任何普通web相关的需求。</p><p>比如URL加密进行防劫持和防盗链，服务端动态生成一串aes加密的URL给CDN，CDN的openresty解密之后用普通的URL转发到后端，然后再返回给用户正确的内容。</p><h1><strong>4.2 tengine</strong></h1><p>淘宝的nginx修改版，实现了很多nginx的收费功能或者是特殊功能，比如动态加载、concat合并请求，动态解析等。</p></div>]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[MySQL表分区（partition）创建、查询、删除以及重建分区等等操作]]></title>
        <id>https://www.plbear.com/post/mysql-partition</id>
        <link href="https://www.plbear.com/post/mysql-partition">
        </link>
        <updated>2019-08-01T14:11:22.000Z</updated>
        <content type="html"><![CDATA[<div><p>下面演示MySQL Range类型分区的操作，其他类型的分区还有Hash、Key、List等等。</p><p>分区优点：</p><p>1. 分区可以分在多个磁盘，存储更大一点。</p><p>2. 根据查找条件，也就是where后面的条件，查找只查找相应的分区不用全部查找了。</p><p>3. 进行大数据搜索时可以进行并行处理。</p><p>4. 跨多个磁盘来分散数据查询，来获得更大的查询吞吐量.</p><h1><strong>1. 创建演示表 tr，设置range 类型分区</strong></h1><blockquote><p>CREATE TABLE tr (id INT, name VARCHAR(50), purchased DATE)</p><p> PARTITION BY RANGE( YEAR(purchased) ) (</p><p> PARTITION p0 VALUES LESS THAN (1990),</p><p> PARTITION p1 VALUES LESS THAN (1995),</p><p> PARTITION p2 VALUES LESS THAN (2000),</p><p> PARTITION p3 VALUES LESS THAN (2005),</p><p> PARTITION p4 VALUES LESS THAN (2010),</p><p> PARTITION p5 VALUES LESS THAN (2015)</p><p>);</p></blockquote><h1><strong>2. 插入演示数据</strong></h1><blockquote><p>INSERT INTO tr VALUES</p><p>(1, 'desk organiser', '2003-10-15'),</p><p>(2, 'alarm clock', '1997-11-05'),</p><p>(3, 'chair', '2009-03-10'),</p><p>(4, 'bookcase', '1989-01-10'),</p><p>(5, 'exercise bike', '2014-05-09'),</p><p>(6, 'sofa', '1987-06-05'),</p><p>(7, 'espresso maker', '2011-11-22'),</p><p>(8, 'aquarium', '1992-08-04'),</p><p>(9, 'study desk', '2006-09-16'),</p><p>(10, 'lava lamp', '1998-12-25');</p></blockquote><p><strong>3. 查询分区 p2中的数据</strong></p><blockquote><p>SELECT * FROM tr</p><p>WHERE purchased BETWEEN '1995-01-01' AND '1999-12-31';</p></blockquote><p>也可以使用分区参数partition 获取相同的信息。</p><h1>SELECT * FROM tr PARTITION (p2);</h1><div class="pgc-img"><img src="http://p1.pstatp.com/large/pgc-image/f4140e2646e9492e9ffa88179cc77f81" img_width="587" img_height="250" alt="MySQL表分区（partition）创建、查询、删除以及重建分区等等操作" inline="0"><p class="pgc-img-caption"></p></div><h1><strong>4. 删除分区</strong></h1><p>下面指定删除分区p2，执行如下命令。</p><blockquote><p>ALTER TABLE tr DROP PARTITION p2;</p></blockquote><p>需要注意的是：<strong>当删除一个分区时，分区中的数据也会被删除。</strong></p><p>再次执行前面的SELECT 脚本，没有任何数据返回。</p><blockquote><p>SELECT * FROM tr</p><p>WHERE purchased BETWEEN '1995-01-01' AND '1999-12-31';</p></blockquote><p>返回结果：0 row(s) returned</p><blockquote><p>SELECT * FROM tr PARTITION (p2);</p></blockquote><p>出现异常：Error Code: 1735. Unknown partition 'p2' in table 'tr'</p><h1><strong>5. 查看表tr的分区定义</strong></h1><blockquote><p>SHOW CREATE TABLE tr;</p></blockquote><div class="pgc-img"><img src="http://p1.pstatp.com/large/pgc-image/f8cd0de264854e089b8d2d345ed7a06e" img_width="513" img_height="269" alt="MySQL表分区（partition）创建、查询、删除以及重建分区等等操作" inline="0"><p class="pgc-img-caption"></p></div><p>partition p2 已经不存在了。</p><p>现在插入 purchased 列数据在1995-01-01 到 2004-12-31 之间的数据，新的行数据将存储在 partition p3中。</p><blockquote><p>INSERT INTO tr VALUES (11, 'pencil holder', '1995-07-12');</p><p>SELECT * FROM tr WHERE purchased BETWEEN '1995-01-01' AND '2004-12-31';</p><p>select * from tr partition(p3);</p></blockquote><div class="pgc-img"><img src="http://p9.pstatp.com/large/pgc-image/748a57d73a7747f0af24463daac5f7c0" img_width="743" img_height="222" alt="MySQL表分区（partition）创建、查询、删除以及重建分区等等操作" inline="0"><p class="pgc-img-caption"></p></div><h1><strong>6. RANGE 重建分区</strong></h1><p>将原来的 p0,p1 分区合并起来，放到新的 p0 分区中。</p><p>在分区合并之前，先检查一下 p0和p1 分区中的数据。</p><p>select * from tr partition(p0,p1);</p><p>输出结果：3条记录</p><div class="pgc-img"><img src="http://p3.pstatp.com/large/pgc-image/01ba2e3ed4054d9a9d4f4f190d1617dd" img_width="421" img_height="182" alt="MySQL表分区（partition）创建、查询、删除以及重建分区等等操作" inline="0"><p class="pgc-img-caption"></p></div><p>下面进行分区合并操作。</p><p>ALTER TABLE tr REORGANIZE PARTITION p0, p1 INTO (PARTITION p0 VALUES LESS THAN (1995));</p><p>合并操作完成之后，分区 p1 已经不存在了，新的 p0 分区数据记录如下，3条记录。</p><p>select * from tr partition(p0);</p><div class="pgc-img"><img src="http://p1.pstatp.com/large/pgc-image/2ee35a9b924841ee8aab57323ce53e76" img_width="420" img_height="186" alt="MySQL表分区（partition）创建、查询、删除以及重建分区等等操作" inline="0"><p class="pgc-img-caption"></p></div><p>查看更新后的分区定义，分区p0的范围进行了重新定义。</p><p>SHOW CREATE TABLE tr;</p><div class="pgc-img"><img src="http://p9.pstatp.com/large/pgc-image/52c3a3b52b0b48d59b1511ca65a5e027" img_width="491" img_height="256" alt="MySQL表分区（partition）创建、查询、删除以及重建分区等等操作" inline="0"><p class="pgc-img-caption"></p></div><p>打开MySQL的数据目录，查看分区的表空间文件如下。</p><div class="pgc-img"><img src="http://p1.pstatp.com/large/pgc-image/8757eccc655e4845aec2b263e6abc1e6" img_width="606" img_height="108" alt="MySQL表分区（partition）创建、查询、删除以及重建分区等等操作" inline="0"><p class="pgc-img-caption"></p></div><h1><strong>7. 子分区</strong></h1><p>子分区是分区表中每个分区的再次分割，子分区既可以使用HASH分区，也可以使用KEY分区。这也被称为复合分区（composite partitioning）。</p><p>子分区的几点注意事项：</p><ul><li>如果一个分区中创建了子分区，其他分区也要有子分区。</li><li>如果创建了子分区，每个分区中的子分区数必有相同。</li><li>同一分区内的子分区，名字不相同，不同分区内的子分区名字可以相同。</li><li>由于分区是RANGE和LIST分区，所以删除分区也是同RANGE和LIST分区一样，这里只能对每个分区进行删除，不能针对每个子分区进行删除操作，删除分区后子分区连同数据一并被删除。</li></ul><p><strong>子分区由两种创建方法：</strong></p><p>一种是不定义每个子分区的名字和路径由分区决定；</p><p>二是定义每个子分区的分区名和各自的路径；</p><p>（1）不定义每个子分区</p><p>表名称：tb_sub</p><blockquote><p>CREATE TABLE tb_sub (id INT, purchased DATE)</p><p> PARTITION BY RANGE( YEAR(purchased) )</p><p> SUBPARTITION BY HASH( TO_DAYS(purchased) )</p><p> SUBPARTITIONS 2 (</p><p> PARTITION p0 VALUES LESS THAN (1990),</p><p> PARTITION p1 VALUES LESS THAN (2000),</p><p> PARTITION p2 VALUES LESS THAN MAXVALUE</p><p> );</p></blockquote><p>分区表空间文件如下。</p><div class="pgc-img"><img src="http://p3.pstatp.com/large/pgc-image/736fdd7f0a9f4f588d85d7bfbccbcf26" img_width="609" img_height="150" alt="MySQL表分区（partition）创建、查询、删除以及重建分区等等操作" inline="0"><p class="pgc-img-caption"></p></div><p>查看系统中表tb_sub 信息：</p><blockquote><p>SELECT PARTITION_NAME,PARTITION_METHOD,PARTITION_EXPRESSION,PARTITION_DESCRIPTION,TABLE_ROWS,SUBPARTITION_NAME,SUBPARTITION_METHOD,SUBPARTITION_EXPRESSION</p><p>FROM information_schema.PARTITIONS</p><p>WHERE TABLE_SCHEMA=SCHEMA() AND TABLE_NAME='tb_sub';</p></blockquote><div class="pgc-img"><img src="http://p3.pstatp.com/large/pgc-image/5b927bdc92f641d9837cec790f803278" img_width="1016" img_height="300" alt="MySQL表分区（partition）创建、查询、删除以及重建分区等等操作" inline="0"><p class="pgc-img-caption"></p></div><p>（2）定义每个子分区</p><p>定义子分区可以为每个子分区定义具体的分区名和分区路径。</p><blockquote><p>CREATE TABLE tb_sub_ev (id INT, purchased DATE)</p><p> PARTITION BY RANGE( YEAR(purchased) )</p><p> SUBPARTITION BY HASH( TO_DAYS(purchased) ) (</p><p> PARTITION p0 VALUES LESS THAN (1990) (</p><p> SUBPARTITION s0,</p><p> SUBPARTITION s1</p><p> ),</p><p> PARTITION p1 VALUES LESS THAN (2000) (</p><p> SUBPARTITION s2,</p><p> SUBPARTITION s3</p><p> ),</p><p> PARTITION p2 VALUES LESS THAN MAXVALUE (</p><p> SUBPARTITION s4,</p><p> SUBPARTITION s5</p><p> )</p><p> );</p></blockquote><p>插入测试记录：</p><blockquote><p>INSERT INTO tb_sub_ev() VALUES(1,'1989-01-01'),(2,'1989-03-19'),(3,'1989-04-19');</p></blockquote><p>从查询结果中，可以看到3条记录分表存储在2个不同的子分区中。</p><div class="pgc-img"><img src="http://p3.pstatp.com/large/pgc-image/9bec9e47cfe9407f9ac5a1350610b12d" img_width="1016" img_height="385" alt="MySQL表分区（partition）创建、查询、删除以及重建分区等等操作" inline="0"><p class="pgc-img-caption"></p></div><p>查看如下查询语言的执行计划：</p><blockquote><p>explain select * from tb_sub where purchased='1989-01-01';</p><p>explain select * from tb_sub where purchased='1989-03-19';</p><p>explain select * from tb_sub where purchased='1989-04-19';</p></blockquote><div class="pgc-img"><img src="http://p1.pstatp.com/large/pgc-image/362381940f1c4c6991fba01dc062149a" img_width="808" img_height="114" alt="MySQL表分区（partition）创建、查询、删除以及重建分区等等操作" inline="0"><p class="pgc-img-caption"></p></div><h1><strong>8. 移除表的分区</strong></h1><p>注意：使用remove移除分区是仅仅移除分区的定义，并不会删除数据和drop PARTITION不一样，后者会连同数据一起删除。</p><p>ALTER TABLE tb_sub REMOVE PARTITIONING;</p><p>移除分区之后，再次查询表中的数据，确认表的数据依然存在。</p><div class="pgc-img"><img src="http://p3.pstatp.com/large/pgc-image/ecf5574015af49259b8e3a153455f093" img_width="459" img_height="246" alt="MySQL表分区（partition）创建、查询、删除以及重建分区等等操作" inline="0"><p class="pgc-img-caption"></p></div><p>查看表结构，确认表分区已经成功移除了。</p><p>show create table tb_sub;</p><div class="pgc-img"><img src="http://p1.pstatp.com/large/pgc-image/2336de35079440b8bded63559396d1b0" img_width="417" img_height="244" alt="MySQL表分区（partition）创建、查询、删除以及重建分区等等操作" inline="0"><p class="pgc-img-caption"></p></div><!----></div>]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[微服务架构基于Mycat分库分表及读写分离的配置实战]]></title>
        <id>https://www.plbear.com/post/mycat</id>
        <link href="https://www.plbear.com/post/mycat">
        </link>
        <updated>2019-08-01T13:57:58.000Z</updated>
        <content type="html"><![CDATA[<div><blockquote><p>本文以在线商城系统为主要业务场景，分别定义了用户、商品和订单三个微服务，并实现三个微服务所涉及到的数据库和表的水平拆分、垂直拆分和读写分离的相关配置。</p></blockquote><h1>概念</h1><p>先来看一下本文业务场景中涉及到的数据库表。</p><div class="pgc-img"><img src="http://p9.pstatp.com/large/pgc-image/4ef055d806c046bcb286caf945fb019e" img_width="161" img_height="256" alt="微服务架构基于Mycat分库分表及读写分离的配置实战" inline="0"><p class="pgc-img-caption">单机环境的数据库结构</p></div><p><strong>1、水平拆分</strong></p><p>将同一个表的数据进行分块保存到不同的数据库中，这些数据库中的表结构完全相同。</p><p>我们把数据库水平拆分成三个数据库，每个数据库中的表结构是完全相同的，不同数据库中表的记录条数不同。</p><div class="pgc-img"><img src="http://p1.pstatp.com/large/pgc-image/6fe8a9205795466886ded8fcdedb0d8e" img_width="519" img_height="544" alt="微服务架构基于Mycat分库分表及读写分离的配置实战" inline="0"><p class="pgc-img-caption">水平拆分后的数据库结构</p></div><p><strong>2、垂直拆分</strong></p><p>按功能模块拆分，比如分为订单库、商品库、用户库...这种方式多个数据库之间的表结构不同。</p><p>按用户库、商品库和订单库实现的不同功能进行垂直拆分。</p><div class="pgc-img"><img src="http://p1.pstatp.com/large/pgc-image/e00c8023747d430797d51fdf0f5be00d" img_width="591" img_height="449" alt="微服务架构基于Mycat分库分表及读写分离的配置实战" inline="0"><p class="pgc-img-caption">垂直拆分数据库结构</p></div><p><strong>3、读写分离</strong></p><p>读写分离一般来说都是通过主从复制（Master-Slave）的方式来同步数据，再通过读写分离（MySQL-Proxy）来提升数据库的并发负载能力这样的方案来进行部署与实施的。</p><div class="pgc-img"><img src="http://p3.pstatp.com/large/pgc-image/cbd8c22935544d82a243d225f3dc9394" img_width="866" img_height="532" alt="微服务架构基于Mycat分库分表及读写分离的配置实战" inline="0"><p class="pgc-img-caption">数据库读写分离架构</p></div><p><strong>4、Mycat介绍</strong></p><p>首先，Mycat是数据库分库分表中间件。这是Mycat官网（http://mycat.io/）定义的一句话。个人理解它相当于一个数据库的代理，将拆分后的数据库在逻辑上重新封装，对外暴露和未拆分之前是同样的数据库结构。</p><p>按照上面的业务场景，将数据库进行垂直拆分再水平拆分。按三个业务模块进行垂直拆分，在分别水平拆分成3个数据库，最后形成9个数据库。再按一主一从的方式进行读写分离配置，即一共18个数据库。</p><div class="pgc-img"><img src="http://p1.pstatp.com/large/pgc-image/137595b896e949e7bfd8dd56a9671501" img_width="1336" img_height="809" alt="微服务架构基于Mycat分库分表及读写分离的配置实战" inline="0"><p class="pgc-img-caption">垂直、水平拆分及读写分离架构</p></div><p>1、 不同的微服务连接Mycat中间件。访问对应业务模块的数据库。</p><p>2、 Mycat中的三个数据库在物理上并不存在，是逻辑上的三个数据库。</p><p>3、 Master将三个业务模块的数据库表进行水平拆分，各库中的表结构相同，数据不同。并作为主数据库完成数据的写操作。</p><p>4、 Slave将三个业务模块的数据库表进行水平拆分，各库中的表结构相同，数据不同。并作为从数据库完成数据的读操作。</p><p>5、 Master和Slave实现数据同步操作。</p><h1>Mycat配置</h1><p><strong>概览</strong></p><p>Mycat官网下载1.6.7-release版本解压后的目录结构包括bin、catlet、conf、lib和version.txt。其中conf目录中存放大量的配置文件，其中最主要的是有server.xml、schema.xml和rule.xml三个文件。</p><p><strong>1、server.xml</strong></p><p>server.xml 包含mycat的系统配置信息，它有两个标签，分别是user和system。</p><p>user标签</p><div class="pgc-img"><img src="http://p1.pstatp.com/large/pgc-image/f45c49c024e74b3a9478f7edeb9b16c7" img_width="970" img_height="466" alt="微服务架构基于Mycat分库分表及读写分离的配置实战" inline="0"><p class="pgc-img-caption">server的user标签</p></div><p>name：user的名称，下面的schema.xml文件中的数据库访问用户名。</p><p>password：访问密码。</p><p>schemas：下面schema.xml文件中的逻辑数据库名称，这里把三个都配置上了，方便操作。</p><p>readOnly：说明此用户只有读权限，没有写权限。上面配置中，如果使用user用户登录，则只能进行读操作。</p><p>system标签：</p><p>这里只着重介绍sequnceHanlderType属性，这里是Mycat主键的生成策略。因为现在是把数据进行了多节点的分片拆分。所以使用主键的自增就会造成主键冲突的问题。</p><p>sequnceHanlderType属性有三个选项。0代表本地文件，1代表数据库方式，2代表时间戳方式。这里可以根据需要自行配置。数据库方式的话需要对dataNode创建一些相关的函数才能使用。本地文件是使用conf/sequence_conf.properties文件内容进行维护的。具体详见该文件的内容。</p><div class="pgc-img"><img src="http://p3.pstatp.com/large/pgc-image/32b7d5cbf1c342c1bf30f8f4f595eed2" img_width="541" img_height="35" alt="微服务架构基于Mycat分库分表及读写分离的配置实战" inline="0"><p class="pgc-img-caption">sequnceHanlderType配置</p></div><p><strong>2、schema.xml</strong></p><p>这里将数据库从逻辑上分为三个，javapupil_user(用户库)、javapupil_goods(商品库)、javapupil_order(订单库)。</p><div class="pgc-img"><img src="http://p3.pstatp.com/large/pgc-image/7c00ec461b08456784e2ae3721443fed" img_width="929" img_height="559" alt="微服务架构基于Mycat分库分表及读写分离的配置实战" inline="0"><p class="pgc-img-caption">schema-table-datanode配置</p></div><p>table配置：</p><p>name：表名。</p><p>primaryKey：表中的主键列名。</p><p>dataNode：数据库表所在的数据节点名称。</p><p>rule：数据插入规则，rule.xml小节中详述。</p><div class="pgc-img"><img src="http://p1.pstatp.com/large/pgc-image/05401142d526494880bc0f9b56832921" img_width="831" img_height="270" alt="微服务架构基于Mycat分库分表及读写分离的配置实战" inline="0"><p class="pgc-img-caption">dataNode配置</p></div><p>dataNode配置：</p><p>name：数据节点名称。</p><p>dataHost：数据主机名称。下面详述。</p><p>database：数据库名称。</p><div class="pgc-img"><img src="http://p3.pstatp.com/large/pgc-image/5a3f6b863ca14942b764c8559dc1d6ce" img_width="1080" img_height="388" alt="微服务架构基于Mycat分库分表及读写分离的配置实战" inline="0"><p class="pgc-img-caption">dataHost配置</p></div><p>name：dataHost的名称。</p><p>balance：负载均衡类型。</p><p>（1）0不开启读写分离机制，所有读操作都发送到当前可用的writeHost 上。</p><p>（2）全部的 readHost 与 stand by writeHost 参与 select 语句的负载均衡，简单的说，当双主双从模式(M1-&gt;S1，M2-&gt;S2，并且 M1 与 M2 互为主备)，正常情况下，M2,S1,S2 都参与 select 语句的负载均衡。</p><p>（3）balance="2"，所有读操作都随机的在 writeHost、 readhost 上分发。</p><p>（4）balance="3"，所有读请求随机的分发到 wiriterHost 对应的 readhost 执行，writerHost 不负担读压力，注意 balance=3 只在 1.4 及其以后版本有，1.3 没有。</p><p>所以，这里使用1和3都是可以的。</p><p>writeType：</p><p>（1）writeType="0", 所有写操作发送到配置的第一个 writeHost，第一个挂了切到还生存的第二个riteHost，重新启动后已切换后的为准，切换记录在配置文件中:dnindex.properties.</p><p>（2）writeType="1"，所有写操作都随机的发送到配置的 writeHost，1.5 以后废弃不推荐。</p><p>heartbeat：心跳，判断该数据库是否存活。</p><p>writeHost：Master写操作的数据库配置</p><p>readHost：Slave读操作的数据库配置。如果有多个Slave，这里可以配置多个。</p><p><strong>3、rule.xml</strong></p><p>规则配置文件。</p><pre>&lt;table name="user" primaryKey="id" dataNode="dn1,dn2,dn3" rule="mod-long" /&gt;<br></pre><p>rule属性的mod-long在此配置文件中进行设置。这里表示的是“取模”规则。</p><p>rule.xml文件中会找到如下代码：</p><div class="pgc-img"><img src="http://p1.pstatp.com/large/pgc-image/ec54c97105c443b28c1926bb19416037" img_width="546" img_height="133" alt="微服务架构基于Mycat分库分表及读写分离的配置实战" inline="0"><p class="pgc-img-caption">mod-long配置</p></div><p>columns：表示利用哪个列进行操作，这里是用id列进行操作。这里的id列必须是整型。</p><p>algorithm：表示具体的算法，这里的算法是mod-long。</p><p>那么mod-long是怎么实现的呢：</p><div class="pgc-img"><img src="http://p3.pstatp.com/large/pgc-image/65fc61b83d1b4598975cd44d7cedc0d4" img_width="764" img_height="94" alt="微服务架构基于Mycat分库分表及读写分离的配置实战" inline="0"><p class="pgc-img-caption">实现mod-long的java类</p></div><p>class：io.mycat.route.funciton.PartitionByMod。取模的算法是通过这个类实现的。</p><p>count：表示一共有几个数据节点，这里配置3个，也就是当生成的id与3取模，得到的余数是几就将该条记录插入到哪个数据库中。比如余数是0，就进入dn1中，余数是1就进入dn2中，余数是2就进入dn3中。</p><h1>应用配置</h1><p><strong>1、数据库连接配置</strong></p><p>本例中因为使用了Mycat作为数据库中间件，代理了数据库的分库分表。所以应用程序只需要连接Mycat中的逻辑数据库javapupil_user、javapupil_goods、javapupil_order即可。</p><p>jdbc:mysql://192.168.1.145:8066/javapupil_user</p><p>jdbc:mysql://192.168.1.145:8066/javapupil_ goods</p><p>jdbc:mysql://192.168.1.145:8066/javapupil_order</p><p>注意：Mycat默认的端口是8066。</p><p><strong>2、sql配置</strong></p><p>当程序需要插入数记录时，在insert into中需要加入如下的Sql代码：</p><p>next value for MYCATSEQ_GLOBAL，这里的GLOBAL是在conf/sequence_conf.properties中进行的配置。</p><div class="pgc-img"><img src="http://p1.pstatp.com/large/pgc-image/57be1f8820844309987b7f329f8eb7c2" img_width="308" img_height="102" alt="微服务架构基于Mycat分库分表及读写分离的配置实战" inline="0"><p class="pgc-img-caption">SEQ_GLOBAL配置</p></div><h1>总结</h1><p>本文着重介绍了基于Mycat的Mysql分库分表及读写分离的配置。使用了垂直和水平相结合的方式对数据库进行拆分。Mycat是一款强大的分库分表的中间件，配置简单，运行稳定。希望本文能给正在研究微服务架构分库分表读写分离的朋友带来一点启发。</p></div>]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[如何写出完美的接口：接口规范定义、接口管理工具推荐]]></title>
        <id>https://www.plbear.com/post/that-is-how-restful-api-workds</id>
        <link href="https://www.plbear.com/post/that-is-how-restful-api-workds">
        </link>
        <updated>2019-07-24T14:09:42.000Z</updated>
        <content type="html"><![CDATA[<div><p> <strong>无规矩不成方圆</strong>，为了开发人员间更好的配合，我特意整理了这么一篇文档供大家参考学习，如有意见、见解，请在评论区留言探讨。</p><p> 接口规范说起来大，其实也就那么几个部分，接口规范、接口管理工具、接口文档编写、开发文档编写。</p><p class="ql-align-justify"><br></p><p><strong>接口规范定义</strong></p><p><strong>一、协议规范</strong></p><p> 为了确保不同系统/模块间的数据交互，需要事先约定好通讯协议，如：TCP、HTTP、HTTPS协议。为了确保数据交互安全，建议使用HTTPS协议。</p><p><strong>二、接口路径规范</strong></p><p> 作为接口路径，为了方便清晰的区分来自不同的系统，可以采用不同系统/模块名作为接口路径前缀。</p><p>格式规范如下：</p><p> 支付模块 /pay/xx</p><p> 订单模块 /order/xx</p><p><strong>三、版本控制规范</strong></p><p> 为了便于后期接口的升级和维护，建议在接口路径中加入版本号，便于管理，实现接口多版本的可维护性。如果你细心留意过的话，你会发现好多框架对外提供的API接口中(如：Eureka)，都带有版本号的。如：接口路径中添加类似"v1"、"v2"等版本号。</p><p>格式规范如下：</p><p> /xx/v1/xx</p><p>更新版本后可以使用v2、v3等、依次递加。</p><p><strong>四、接口命名规范</strong></p><p> 和Java命名规范一样，好的、统一的接口命名规范，不仅可以增强其可读性，而且还会减少很多不必要的口头/书面上的解释。</p><p> 可结合【接口路径规范】、【版本控制规范】，外加<strong>具体接口命名</strong>(路径中可包含请求数据，如：id等)，建议具体接口命名也要规范些，可使用"<strong>驼峰命名法</strong>"按照实现接口的业务类型、业务场景等命名，有必要时可采取多级目录命名，但目录不宜过长，两级目录较为适宜。</p><p>格式规范如下：</p><p> /user/v1/sys/login 用户服务/模块的系统登录接口</p><p> /zoo/v1/zoos/{ID} 动物园服务/模块中，获取id为ID的动物</p><p>具体接口命名，通常有以下两种方式：</p><ul><li class="ql-align-justify">接口名称动词前/后缀化</li></ul><p> 接口名称以接口数据操作的动词为前/后缀，常见动词有：add、delete、update、query、get、send、save、detail、list等，如：新建用户addUser、查询订单详情queryOrderDetail。</p><ul><li class="ql-align-justify">接口名称动词+请求方式</li></ul><p> 接口路径中包含具体接口名称的名词，接口数据操作动作以HTTP请求方式来区分。常用的HTTP请求方式有：</p><p> <strong>GET</strong>：从服务器取出资源（一项或多项）。</p><p> <strong>POST</strong>：在服务器新建一个资源。</p><p> <strong>PUT</strong>：在服务器更新资源（客户端提供改变后的完整资源）。</p><p> <strong>PATCH</strong>：在服务器更新资源（客户端提供改变的属性）。</p><p> <strong>DELETE</strong>：从服务器删除资源。</p><p>如：</p><p> GET /zoo/v1/zoos：列出所有动物园</p><p> POST /zoo/v1/zoos：新建一个动物园</p><p> GET /zoo/v1/zoos/{ID}：获取某个指定动物园的信息</p><p> PUT /zoo/v1/zoos/{ID}：更新某个指定动物园的信息（提供该动物园的全部信息）</p><p> PATCH /zoo/v1/zoos/{ID}：更新某个指定动物园的信息（提供该动物园的部分信息）</p><p> DELETE /zoo/v1/zoos/{ID}：删除某个动物园</p><p> GET /zoo/v1/zoos/{ID}/animals：列出某个指定动物园的所有动物</p><p> DELETE /zoo/v1/zoos/ID/animals/ID：删除某个指定动物园的指定动物</p><p class="ql-align-justify"><br></p><p><strong>五、请求参数规范</strong></p><ul><li class="ql-align-justify">请求方式：</li><li class="ql-align-justify">按照GET、POST、PUT等含义定义，避免出现不一致现象，对人造成误解、歧义。</li><li class="ql-align-justify">请求头：</li><li class="ql-align-justify">请求头根据项目需求添加配置参数。如：请求数据格式，accept=‘application/json’等。如有需要，请求头可根据项目需求要求传入用户token、唯一验签码等加密数据。</li><li class="ql-align-justify">请求参数/请求体：</li></ul><p> 请求参数字段，尽可能与数据库表字段、对象属性名等保持一致，因为保持一致最省事，最舒服的一件事。</p><p><strong>六、返回数据规范</strong></p><p> 统一规范返回数据的格式，对己对彼都有好处，此处以json格式为例。返回数据应包含：<strong>返回状态码</strong>、<strong>返回状态信息</strong>、<strong>具体数据。</strong></p><p>格式规范如下：</p><pre>{<br> "status":"000000",<br> "msg":"success",<br> "data": {<br> //json格式的具体数据<br> }<br>}<br></pre><p><strong>接口管理工具推荐</strong></p><p> 接口开发完后，最终的目的是提供给其他系统/模块来使用的，因此，接口的管理是必不可少的。</p><p><strong>接口管理的痛点</strong></p><p> 接口的管理常常面临很多的痛苦，这里就列举几个常见的，看看你是否也遇到过。</p><ul><li class="ql-align-justify">系统/模块太多、接口太多，没有系统统一管理所有接口。</li><li class="ql-align-justify">代码修改后，接口文档没有及时更新，造成接口文档和实际接口不一致的现象。</li><li class="ql-align-justify">接口管理系统自主研开发成本高。</li><li class="ql-align-justify">接口管理缺少接口mock功能。</li></ul><p><strong>接口管理工具推荐</strong></p><p> 在日常工作过程中用过、接触过的接口管理工具也是不尽其数，下面介绍你可能使用过、没有使用过的接口管理工具，同时也介绍这些接口管理工具的优缺点。 </p><p><strong>word</strong></p><p> 相信大家之前用来管理接口比较多的应该是word吧，开发人员将系统的接口维护在word文档里，不管是组内沟通还是和其他团队的接口沟通都离不开这些接口文档，每次修改文档和代码都要同步修改。相信使用word的缺点大家应该也很清楚，就是维护和管理很麻烦，我们经常会遇到<strong>文档和代码不一致</strong>的情况，大部分不一致都是因为接口因为种种原因修改了，开发人员大部分都是只改了代码里的接口实现，而没有去修改接口文档。而且word文档搜索接口也很麻烦，没办法建全局索引，只能一个个文档点开查看，想想就很痛苦。但不可否认的是，word对于一些小团队用起来还是挺方便的，不用搭建系统，给谁一看就明白。</p><p class="ql-align-justify"><br></p><p><strong>自建接口管理系统</strong></p><p> 对于一些有一定规模的企业，在各项工程管理活动上都非常正规，各种ISO标准要遵守，自然对接口管理的要求也非常高，之前在国有银行，我们就是自建了接口管理系统，自建还是很消<strong>耗人力成本</strong>的，从开发到后续运维，都要<strong>消耗人力</strong>，但是自建的好处就是，可以根据公司的要求进行各种花样的定制，我们之前在接口管理系统中加入了很多好用的定制功能，例如接口被哪些系统调用、接口是在哪个批次投产又在哪个批次做过变更等等，这对于架构师来说非常好用，用于分析接口影响范围非常方便。目前开源的接口管理系统还没有能做到这些定制化功能的。</p><p><strong>wiki</strong></p><p> 之前在小团队的时候还用过一段时间的私有wiki，wiki特别适合于小团队高速线性迭代开发，在wiki上看到的就是最新的接口，团队内所有成员看到的都是一样的，如果接口有变化，相关开发人员修改后立即生效，保证了顺畅的接口沟通。但是wiki的缺点也很多，接口文档只是静态页面，<strong>无法实现一些动态效果</strong>，无法实现追溯等等缺点。</p><p><strong>RAP</strong></p><p> 相信很多互联网公司都在使用RAP，RAP是阿里开源的一套接口管理系统，RAP可以比较方便的管理公司所有系统的接口，同时还有比较完善的权限管理，还可以做接口mock，方便开发人员在接口功能还没有完成的时候能够及时发布出去，给调用方去使用。但是RAP的缺点就是每个接口都需要维护进去，接口修改后也需要及时维护，当时我们在使用的时候遇到的最大的问题也是经常碰到接口没有及时维护的问题。</p><p><strong>swagger</strong></p><p class="ql-align-center"><br></p><div class="pgc-img"><img src="http://p1.pstatp.com/large/pgc-image/70132de473a14bffbc577d64af355b95" img_width="532" img_height="173" alt="如何写出完美的接口：接口规范定义、接口管理工具推荐" inline="0"><p class="pgc-img-caption"></p></div><p class="ql-align-center"><br></p><p class="ql-align-justify"> 上面说的那些接口管理工具，其实都有一个很大的问题就是修改代码后需要同步维护接口文档，但是让程序员去修改文档是很难的，大部分程序员都比较讨厌维护各类文档。当我第一次了解到swagger的时候，发现这简直就是为程序员定制的接口管理工具，swagger定义了很多注解，在对接口加上swagger相关的注解，当接口代码修改后，swagger在工程启动后会根据代码自动生成最新的接口html文档，同时swagger提供了mock接口模拟的功能，也能够更加方便的模拟接口，并且还能够在swagger界面上直接发起接口调用，可以方便调用方在还没写代码的时候就能够尝试下接口调用后的结果。</p><p> 看了那么多swagger的优点，下面也说说swagger的缺点，那就是swagger是跟随着每个工程一起启动的，这就导致每个工程都有一个swagger的访问地址，如果公司系统很多的话，那就会导致查看不同系统的接口都要到不同的地址去查看，每个开发都要自己收藏好各个系统的swagger地址。有些公司也自己开发了统一网关，将所有swagger的接口地址聚合起来，但是多少还是涉及到一些开发工作的，而且做的还不一定很完善。</p><p><strong>Easy Mock</strong></p><p class="ql-align-center"><br></p><div class="pgc-img"><img src="http://p1.pstatp.com/large/pgc-image/5f8b8653282d44318f49479b6b03e071" img_width="1080" img_height="670" alt="如何写出完美的接口：接口规范定义、接口管理工具推荐" inline="0"><p class="pgc-img-caption"></p></div><p class="ql-align-center"><br></p><p> 官网的这张图基本上介绍清楚了easymock的核心功能，这其中我最看重的功能有两块，一个是能够集成swagger接口并集中管理所有接口，另一个就是响应式数据。</p><p> EasyMock能够根据swagger接口的地址自动导入所有swagger接口，非常方便，对于非swagger的接口也可以手工维护进去，这样可以很方便的做到全公司接口统一维护，而且也有比较完善的接口权限管理，方便分组管理。但缺点就是过于庞大，可能太适合小一点项目或团队。</p><p class="ql-align-justify"> 上面提及到接口管理工具，大家可根据自己项目的规模、需求，进行实际选择，切记生搬硬套。</p></div>]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[这可能是最为详细的Docker入门吐血总结]]></title>
        <id>https://www.plbear.com/post/awesome-docker-get-start</id>
        <link href="https://www.plbear.com/post/awesome-docker-get-start">
        </link>
        <updated>2019-07-22T14:40:23.000Z</updated>
        <content type="html"><![CDATA[<div><p class="ql-align-justify">在计算机技术日新月异的今天， Docker 在国内发展的如火如荼。</p><p class="ql-align-center"><br></p><div class="pgc-img"><img src="http://p1.pstatp.com/large/pgc-image/1540437482919069761a6bf" img_width="600" img_height="320" alt="这可能是最为详细的Docker入门吐血总结" inline="0"><p class="pgc-img-caption"></p></div><p class="ql-align-center"><br></p><p class="ql-align-justify">特别是在一线互联网公司 Docker 的使用是十分普遍的，甚至成为了一些企业面试的加分项，不信的话看看下面这张图。</p><p class="ql-align-center"><br></p><div class="pgc-img"><img src="http://p1.pstatp.com/large/pgc-image/15404374832194c7c2d4160" img_width="500" img_height="354" alt="这可能是最为详细的Docker入门吐血总结" inline="0"><p class="pgc-img-caption"></p></div><p class="ql-align-center"><br></p><p class="ql-align-justify">这是我在某招聘网站上看到的招聘 Java 开发工程师的招聘要求，其中有一条熟悉 Docker 成为了你快速入职的加分项，由此可见熟悉 Docker 在互联网公司的地位之重要。</p><p class="ql-align-justify">市面上已经有很多优秀的 Docker 教程，但是很多原理性的东西，笔者认为那些教程对初学者而言还是很难理解，感觉没有说清楚(笔者自己都觉得挺懵逼的)。</p><p class="ql-align-justify">为了让初学者少走弯路，我将以我的学习经历以及作为一个 CTF 的角度，编写此套教程，来带大家去了解并熟练运用 Docker 。</p><p class="ql-align-justify"><strong>Docker 是什么?</strong></p><p class="ql-align-justify">说了这么多， Docker 到底是个什么东西呢?我们在理解 Docker 之前，首先得先区分清楚两个概念，容器和虚拟机。</p><p class="ql-align-justify">可能很多读者朋友都用过虚拟机，而对容器这个概念比较的陌生。我们用的传统虚拟机如 VMware ， VisualBox 之类的需要模拟整台机器包括硬件。</p><p class="ql-align-justify">每台虚拟机都需要有自己的操作系统，虚拟机一旦被开启，预分配给它的资源将全部被占用。</p><p class="ql-align-justify">每一台虚拟机包括应用，必要的二进制和库，以及一个完整的用户操作系统。</p><p class="ql-align-justify">而容器技术是和我们的宿主机共享硬件资源及操作系统，可以实现资源的动态分配。</p><p class="ql-align-justify">容器包含应用和其所有的依赖包，但是与其他容器共享内核。容器在宿主机操作系统中，在用户空间以分离的进程运行。</p><p class="ql-align-justify">容器技术是实现操作系统虚拟化的一种途径，可以让您在资源受到隔离的进程中运行应用程序及其依赖关系。</p><p class="ql-align-justify">通过使用容器，我们可以轻松打包应用程序的代码、配置和依赖关系，将其变成容易使用的构建块，从而实现环境一致性、运营效率、开发人员生产力和版本控制等诸多目标。</p><p class="ql-align-justify">容器可以帮助保证应用程序快速、可靠、一致地部署，其间不受部署环境的影响。</p><p class="ql-align-justify">容器还赋予我们对资源更多的精细化控制能力，让我们的基础设施效率更高。</p><p class="ql-align-justify">通过下面这幅图，我们可以很直观的反映出这两者的区别所在：</p><p class="ql-align-center"><br></p><div class="pgc-img"><img src="http://p1.pstatp.com/large/pgc-image/154043748298764b5cbeafd" img_width="500" img_height="258" alt="这可能是最为详细的Docker入门吐血总结" inline="0"><p class="pgc-img-caption"></p></div><p class="ql-align-center"><br></p><p class="ql-align-justify">Docker 属于 Linux 容器的一种封装，提供简单易用的容器使用接口。它是目前最流行的 Linux 容器解决方案。</p><p class="ql-align-justify">而 Linux 容器是 Linux 发展出的另一种虚拟化技术，简单来讲， Linux 容器不是模拟一个完整的操作系统，而是对进程进行隔离，相当于是在正常进程的外面套了一个保护层。</p><p class="ql-align-justify">对于容器里面的进程来说，它接触到的各种资源都是虚拟的，从而实现与底层系统的隔离。</p><p class="ql-align-justify">Docker 将应用程序与该程序的依赖，打包在一个文件里面。运行这个文件，就会生成一个虚拟容器。</p><p class="ql-align-justify">程序在这个虚拟容器里运行，就好像在真实的物理机上运行一样。有了 Docker ，就不用担心环境问题。</p><p class="ql-align-justify">总体来说，Docker 的接口相当简单，用户可以方便地创建和使用容器，把自己的应用放入容器。容器还可以进行版本管理、复制、分享、修改，就像管理普通的代码一样。</p><p class="ql-align-justify"><strong>Docker 的优势</strong></p><p class="ql-align-justify">Docker 相比于传统虚拟化方式具有更多的优势：</p><ul><li>Docker 启动快速属于秒级别。虚拟机通常需要几分钟去启动。</li><li>Docker 需要的资源更少。Docker 在操作系统级别进行虚拟化，Docker 容器和内核交互，几乎没有性能损耗，性能优于通过 Hypervisor 层与内核层的虚拟化。</li><li>Docker 更轻量。Docker 的架构可以共用一个内核与共享应用程序库，所占内存极小。同样的硬件环境，Docker 运行的镜像数远多于虚拟机数量，对系统的利用率非常高。</li><li>与虚拟机相比，Docker 隔离性更弱。Docker 属于进程之间的隔离，虚拟机可实现系统级别隔离。</li><li>安全性。Docker 的安全性也更弱，Docker 的租户 Root 和宿主机 Root 等同，一旦容器内的用户从普通用户权限提升为 Root 权限，它就直接具备了宿主机的 Root 权限，进而可进行无限制的操作。</li></ul><p class="ql-align-justify">虚拟机租户 Root 权限和宿主机的 Root 虚拟机权限是分离的，并且虚拟机利用如 Intel 的 VT-d 和 VT-x 的 ring-1 硬件隔离技术。</p><p class="ql-align-justify">这种隔离技术可以防止虚拟机突破和彼此交互，而容器至今还没有任何形式的硬件隔离，这使得容器容易受到攻击。</p><ul><li>可管理性。Docker 的集中化管理工具还不算成熟。各种虚拟化技术都有成熟的管理工具，例如 VMware vCenter 提供完备的虚拟机管理能力。</li><li>高可用和可恢复性。Docker 对业务的高可用支持是通过快速重新部署实现的。</li><li>虚拟化具备负载均衡，高可用，容错，迁移和数据保护等经过生产实践检验的成熟保障机制， VMware 可承诺虚拟机 99.999% 高可用，保证业务连续性。</li><li>快速创建、删除。虚拟化创建是分钟级别的，Docker 容器创建是秒级别的，Docker 的快速迭代性，决定了无论是开发、测试、部署都可以节约大量时间</li><li>交付、部署。虚拟机可以通过镜像实现环境交付的一致性，但镜像分发无法体系化。Docker 在 Dockerfile 中记录了容器构建过程，可在集群中实现快速分发和快速部署。</li></ul><p class="ql-align-justify">我们可以从下面这张表格很清楚地看到容器相比于传统虚拟机的特性的优势所在：</p><p class="ql-align-center"><br></p><div class="pgc-img"><img src="http://p1.pstatp.com/large/pgc-image/15404374829284f427c013d" img_width="500" img_height="248" alt="这可能是最为详细的Docker入门吐血总结" inline="0"><p class="pgc-img-caption"></p></div><p class="ql-align-center"><br></p><p class="ql-align-justify"><strong>Docker 的三个基本概念</strong></p><p class="ql-align-center"><br></p><div class="pgc-img"><img src="http://p1.pstatp.com/large/pgc-image/15404374829469eea2fc391" img_width="500" img_height="375" alt="这可能是最为详细的Docker入门吐血总结" inline="0"><p class="pgc-img-caption"></p></div><p class="ql-align-center"><br></p><p class="ql-align-justify">从上图我们可以看到，Docker 中包括三个基本的概念：</p><ul><li><strong>Image(镜像)</strong></li><li><strong>Container(容器)</strong></li><li><strong>Repository(仓库)</strong></li></ul><p class="ql-align-justify">镜像是 Docker 运行容器的前提，仓库是存放镜像的场所，可见镜像更是 Docker 的核心。</p><p class="ql-align-justify"><strong>Image(镜像)</strong></p><p class="ql-align-justify">那么镜像到底是什么呢?Docker 镜像可以看作是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数(如匿名卷、环境变量、用户等)。</p><p class="ql-align-justify">镜像不包含任何动态数据，其内容在构建之后也不会被改变。镜像(Image)就是一堆只读层(read-only layer)的统一视角，也许这个定义有些难以理解，下面的这张图能够帮助读者理解镜像的定义：</p><p class="ql-align-center"><br></p><div class="pgc-img"><img src="http://p1.pstatp.com/large/pgc-image/1540437483061d74da9b80d" img_width="624" img_height="187" alt="这可能是最为详细的Docker入门吐血总结" inline="0"><p class="pgc-img-caption"></p></div><p class="ql-align-center"><br></p><p class="ql-align-justify">从左边我们看到了多个只读层，它们重叠在一起。除了最下面一层，其他层都会有一个指针指向下一层。这些层是 Docker 内部的实现细节，并且能够在主机的文件系统上访问到。</p><p class="ql-align-justify">统一文件系统(Union File System)技术能够将不同的层整合成一个文件系统，为这些层提供了一个统一的视角。</p><p class="ql-align-justify">这样就隐藏了多层的存在，在用户的角度看来，只存在一个文件系统。我们可以在图片的右边看到这个视角的形式。</p><p class="ql-align-justify"><strong>Container(容器)</strong></p><p class="ql-align-justify">容器(Container)的定义和镜像(Image)几乎一模一样，也是一堆层的统一视角，唯一区别在于容器的最上面那一层是可读可写的。</p><p class="ql-align-center"><br></p><div class="pgc-img"><img src="http://p3.pstatp.com/large/pgc-image/1540437483094ad5d26853a" img_width="500" img_height="133" alt="这可能是最为详细的Docker入门吐血总结" inline="0"><p class="pgc-img-caption"></p></div><p class="ql-align-center"><br></p><p class="ql-align-justify">由于容器的定义并没有提及是否要运行容器，所以实际上，容器 = 镜像 + 读写层。</p><p class="ql-align-justify"><strong>Repository(仓库)</strong></p><p class="ql-align-justify">Docker 仓库是集中存放镜像文件的场所。镜像构建完成后，可以很容易的在当前宿主上运行。</p><p class="ql-align-justify">但是， 如果需要在其他服务器上使用这个镜像，我们就需要一个集中的存储、分发镜像的服务，Docker Registry(仓库注册服务器)就是这样的服务。</p><p class="ql-align-justify">有时候会把仓库(Repository)和仓库注册服务器(Registry)混为一谈，并不严格区分。</p><p class="ql-align-justify">Docker 仓库的概念跟 Git 类似，注册服务器可以理解为 GitHub 这样的托管服务。</p><p class="ql-align-justify">实际上，一个 Docker Registry 中可以包含多个仓库(Repository)，每个仓库可以包含多个标签(Tag)，每个标签对应着一个镜像。</p><p class="ql-align-justify">所以说，镜像仓库是 Docker 用来集中存放镜像文件的地方，类似于我们之前常用的代码仓库。</p><p class="ql-align-justify">通常，一个仓库会包含同一个软件不同版本的镜像，而标签就常用于对应该软件的各个版本 。</p><p class="ql-align-justify">我们可以通过&lt;仓库名&gt;:&lt;标签&gt;的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签，将以 Latest 作为默认标签。</p><p class="ql-align-justify">仓库又可以分为两种形式：</p><ul><li><strong>Public(公有仓库)</strong></li><li><strong>Private(私有仓库)</strong></li></ul><p class="ql-align-justify">Docker Registry 公有仓库是开放给用户使用、允许用户管理镜像的 Registry 服务。</p><p class="ql-align-justify">一般这类公开服务允许用户免费上传、下载公开的镜像，并可能提供收费服务供用户管理私有镜像。</p><p class="ql-align-justify">除了使用公开服务外，用户还可以在本地搭建私有 Docker Registry。Docker 官方提供了 Docker Registry 镜像，可以直接使用做为私有 Registry 服务。</p><p class="ql-align-justify">当用户创建了自己的镜像之后就可以使用 Push 命令将它上传到公有或者私有仓库，这样下次在另外一台机器上使用这个镜像时候，只需要从仓库上 Pull 下来就可以了。</p><p class="ql-align-justify">我们主要把 Docker 的一些常见概念如 Image，Container，Repository 做了详细的阐述，也从传统虚拟化方式的角度阐述了 Docker 的优势。</p><p class="ql-align-justify">我们从下图可以直观地看到 Docker 的架构：</p><p class="ql-align-center"><br></p><div class="pgc-img"><img src="http://p1.pstatp.com/large/pgc-image/1540437483066b438f353af" img_width="500" img_height="377" alt="这可能是最为详细的Docker入门吐血总结" inline="0"><p class="pgc-img-caption"></p></div><p class="ql-align-center"><br></p><p class="ql-align-justify">Docker 使用 C/S 结构，即客户端/服务器体系结构。Docker 客户端与 Docker 服务器进行交互，Docker服务端负责构建、运行和分发 Docker 镜像。</p><p class="ql-align-justify">Docker 客户端和服务端可以运行在一台机器上，也可以通过 RESTful 、 Stock 或网络接口与远程 Docker 服务端进行通信。</p><p class="ql-align-center"><br></p><div class="pgc-img"><img src="http://p1.pstatp.com/large/pgc-image/1540437483930f2eea202cd" img_width="500" img_height="260" alt="这可能是最为详细的Docker入门吐血总结" inline="0"><p class="pgc-img-caption"></p></div><p class="ql-align-center"><br></p><p class="ql-align-justify">这张图展示了 Docker 客户端、服务端和 Docker 仓库(即 Docker Hub 和 Docker Cloud )，默认情况下 Docker 会在 Docker 中央仓库寻找镜像文件。</p><p class="ql-align-justify">这种利用仓库管理镜像的设计理念类似于 Git ，当然这个仓库是可以通过修改配置来指定的，甚至我们可以创建我们自己的私有仓库。</p><p class="ql-align-justify"><strong>Docker 的安装和使用</strong></p><p class="ql-align-justify">Docker 的安装和使用有一些前提条件，主要体现在体系架构和内核的支持上。</p><p class="ql-align-justify">对于体系架构，除了 Docker 一开始就支持的 X86-64 ，其他体系架构的支持则一直在不断地完善和推进中。</p><p class="ql-align-justify">Docker 分为 CE 和 EE 两大版本。CE 即社区版，免费支持周期 7 个月;EE 即企业版，强调安全，付费使用，支持周期 24 个月。</p><p class="ql-align-justify">我们在安装前可以参看官方文档获取最新的 Docker 支持情况，官方文档在这里：</p><pre>https://docs.docker.com/install/ <br></pre><p class="ql-align-justify">Docker 对于内核支持的功能，即内核的配置选项也有一定的要求(比如必须开启 Cgroup 和 Namespace 相关选项，以及其他的网络和存储驱动等)。</p><p class="ql-align-justify">Docker 源码中提供了一个检测脚本来检测和指导内核的配置，脚本链接在这里：</p><pre>https://raw.githubusercontent.com/docker/docker/master/contrib/check-config.sh <br></pre><p class="ql-align-justify">在满足前提条件后，安装就变得非常的简单了。</p><p class="ql-align-justify">Docker CE 的安装请参考官方文档：</p><ul><li>MacOS：https://docs.docker.com/docker-for-mac/install/</li><li>Windows：https://docs.docker.com/docker-for-windows/install/</li><li>Ubuntu：https://docs.docker.com/install/linux/docker-ce/ubuntu/</li><li>Debian：https://docs.docker.com/install/linux/docker-ce/debian/</li><li>CentOS：https://docs.docker.com/install/linux/docker-ce/centos/</li><li>Fedora：https://docs.docker.com/install/linux/docker-ce/fedora/</li><li>其他 Linux 发行版：https://docs.docker.com/install/linux/docker-ce/binaries/</li></ul><p class="ql-align-justify">这里我们以 CentOS 7 作为演示。</p><p class="ql-align-justify">环境准备：</p><p class="ql-align-justify">阿里云服务器(1 核 2G，1M 带宽)</p><p class="ql-align-justify">CentOS 7.4 64 位</p><p class="ql-align-justify">由于 Docker-CE 支持 64 位版本的 CentOS 7 ，并且要求内核版本不低于 3.10，首先我们需要卸载掉旧版本的 Docker：</p><pre>$ sudo yum remove docker \ <br> docker-client \ <br> docker-client-latest \ <br> docker-common \ <br> docker-latest \ <br> docker-latest-logrotate \ <br> docker-logrotate \ <br> docker-selinux \ <br> docker-engine-selinux \ <br> docker-engine <br></pre><p class="ql-align-center"><br></p><div class="pgc-img"><img src="http://p1.pstatp.com/large/pgc-image/154043748342493d1d90968" img_width="500" img_height="245" alt="这可能是最为详细的Docker入门吐血总结" inline="0"><p class="pgc-img-caption"></p></div><p class="ql-align-center"><br></p><p class="ql-align-justify">我们执行以下安装命令去安装依赖包：</p><pre>$ sudo yum install -y yum-utils \ <br> device-mapper-persistent-data \ <br> lvm2 <br></pre><p class="ql-align-justify">这里我事先已经安装过了，所以提示我已经安装了最新版本：</p><p class="ql-align-center"><br></p><div class="pgc-img"><img src="http://p1.pstatp.com/large/pgc-image/15404374833954cb9ab6494" img_width="500" img_height="251" alt="这可能是最为详细的Docker入门吐血总结" inline="0"><p class="pgc-img-caption"></p></div><p class="ql-align-center"><br></p><p class="ql-align-justify"><strong>安装 Docker</strong></p><p class="ql-align-justify">Docker 软件包已经包括在默认的 CentOS-Extras 软件源里。因此想要安装 Docker，只需要运行下面的 yum 命令：</p><pre>$ sudo yum install docker <br></pre><p class="ql-align-justify">当然在测试或开发环境中 Docker 官方为了简化安装流程，提供了一套便捷的安装脚本，CentOS 系统上可以使用这套脚本安装：</p><pre>curl -fsSL get.docker.com -o get-docker.shsh get-docker.sh <br></pre><p class="ql-align-justify">具体可以参看 docker-install 的脚本：</p><pre>https://github.com/docker/docker-install <br></pre><p class="ql-align-justify">执行这个命令后，脚本就会自动的将一切准备工作做好，并且把 Docker CE 的 Edge 版本安装在系统中。</p><p class="ql-align-justify">安装完成后，运行下面的命令，验证是否安装成功：</p><pre>docker versionordocker info <br></pre><p class="ql-align-justify">返回 Docker 的版本相关信息，证明 Docker 安装成功：</p><p class="ql-align-center"><br></p><div class="pgc-img"><img src="http://p3.pstatp.com/large/pgc-image/1540437483440cc168b70cc" img_width="500" img_height="310" alt="这可能是最为详细的Docker入门吐血总结" inline="0"><p class="pgc-img-caption"></p></div><p class="ql-align-center"><br></p><p class="ql-align-justify">启动 Docker-CE：</p><pre>$ sudo systemctl enable docker$ sudo systemctl start docker <br></pre><p class="ql-align-justify"><strong>Docker 的简单运用 Hello World</strong></p><p class="ql-align-justify">由于服务器日常崩溃了， Docker 出了点问题，所以以下案例的演示是基于 Kali Linux 环境下进行的。</p><p class="ql-align-justify">我们通过最简单的 Image 文件 Hello World，感受一下 Docker 的魅力吧!</p><p class="ql-align-justify">我们直接运行下面的命令，将名为 hello-world 的 image 文件从仓库抓取到本地：</p><pre>docker pull library/hello-world <br></pre><p class="ql-align-justify">docker pull images 是抓取 image 文件，library/hello-world 是 image 文件在仓库里面的位置，其中 library 是 image 文件所在的组，hello-world 是 image 文件的名字。</p><p class="ql-align-center"><br></p><div class="pgc-img"><img src="http://p1.pstatp.com/large/pgc-image/15404374834973408bf20f3" img_width="500" img_height="93" alt="这可能是最为详细的Docker入门吐血总结" inline="0"><p class="pgc-img-caption"></p></div><p class="ql-align-center"><br></p><p class="ql-align-justify">抓取成功以后，就可以在本机看到这个 image 文件了：</p><pre>docker images <br></pre><p class="ql-align-justify">我们可以看到如下结果：</p><p class="ql-align-center"><br></p><div class="pgc-img"><img src="http://p1.pstatp.com/large/pgc-image/15404374835181c6b718c94" img_width="500" img_height="68" alt="这可能是最为详细的Docker入门吐血总结" inline="0"><p class="pgc-img-caption"></p></div><p class="ql-align-center"><br></p><p class="ql-align-justify">现在，我们可以运行 hello-world 这个 image 文件：</p><pre>docker run hello-world <br></pre><p class="ql-align-justify">我们可以看到如下结果：</p><p class="ql-align-center"><br></p><div class="pgc-img"><img src="http://p1.pstatp.com/large/pgc-image/1540437483633734d823ba4" img_width="500" img_height="263" alt="这可能是最为详细的Docker入门吐血总结" inline="0"><p class="pgc-img-caption"></p></div><p class="ql-align-center"><br></p><p class="ql-align-justify">输出这段提示以后，hello world 就会停止运行，容器自动终止。有些容器不会自动终止，因为提供的是服务，比如 MySQL 镜像等。</p><p class="ql-align-justify">是不是很 Easy 呢?我们从上面可以看出，Docker 的功能是十分强大的，除此之外，我们还可以拉取一些 Ubuntu，Apache 等镜像，在未来的教程中我们将会一一提到。</p><p class="ql-align-justify">Docker 提供了一套简单实用的命令来创建和更新镜像，我们可以通过网络直接下载一个已经创建好了的应用镜像，并通过 Docker RUN 命令就可以直接使用。</p><p class="ql-align-justify">当镜像通过 RUN 命令运行成功后，这个运行的镜像就是一个 Docker 容器啦。</p><p class="ql-align-justify">容器可以理解为一个轻量级的沙箱，Docker 利用容器来运行和隔离应用，容器是可以被启动、停止、删除的，这并不会影响 Docker 镜像。</p><p class="ql-align-justify">我们可以看看下面这幅图：</p><p class="ql-align-center"><br></p><div class="pgc-img"><img src="http://p3.pstatp.com/large/pgc-image/1540437483581057a285a71" img_width="500" img_height="391" alt="这可能是最为详细的Docker入门吐血总结" inline="0"><p class="pgc-img-caption"></p></div><p class="ql-align-center"><br></p><p class="ql-align-justify">Docker 客户端是 Docker 用户与 Docker 交互的主要方式。当您使用 Docker 命令行运行命令时，Docker 客户端将这些命令发送给服务器端，服务端将执行这些命令。</p><p class="ql-align-justify">Docker 命令使用 Docker API 。Docker 客户端可以与多个服务端进行通信。</p><p class="ql-align-justify">我们将剖析一下 Docker 容器是如何工作的，学习好 Docker 容器工作的原理，我们就可以自己去管理我们的容器了。</p><p class="ql-align-justify"><strong>Docker 架构</strong></p><p class="ql-align-justify">在上面的学习中，我们简单地讲解了 Docker 的基本架构。了解到了 Docker 使用的是 C/S 结构，即客户端/服务器体系结构。</p><p class="ql-align-justify">明白了 Docker 客户端与 Docker 服务器进行交互时，Docker 服务端负责构建、运行和分发 Docker 镜像。</p><p class="ql-align-justify">知道了 Docker 客户端和服务端可以运行在一台机器上，我们可以通过 RESTful 、Stock 或网络接口与远程 Docker 服务端进行通信。</p><p class="ql-align-justify">我们从下图可以很直观的了解到 Docker 的架构：</p><p class="ql-align-center"><br></p><div class="pgc-img"><img src="http://p1.pstatp.com/large/pgc-image/154043748363888b604c0ab" img_width="500" img_height="260" alt="这可能是最为详细的Docker入门吐血总结" inline="0"><p class="pgc-img-caption"></p></div><p class="ql-align-center"><br></p><p class="ql-align-justify">Docker 的核心组件包括：</p><ul><li>Docker Client</li><li>Docker Daemon</li><li>Docker Image</li><li>Docker Registry</li><li>Docker Container</li></ul><p class="ql-align-justify">Docker 采用的是 Client/Server 架构。客户端向服务器发送请求，服务器负责构建、运行和分发容器。</p><p class="ql-align-justify">客户端和服务器可以运行在同一个 Host 上，客户端也可以通过 Socket 或 REST API 与远程的服务器通信。</p><p class="ql-align-justify">可能很多朋友暂时不太理解一些东西，比如 REST API 是什么东西等，不过没关系，在后面的文章中会一一给大家讲解清楚。</p><p class="ql-align-justify"><strong>Docker Client</strong></p><p class="ql-align-justify">Docker Client ，也称 Docker 客户端。它其实就是 Docker 提供命令行界面(CLI)工具，是许多 Docker 用户与 Docker 进行交互的主要方式。</p><p class="ql-align-justify">客户端可以构建，运行和停止应用程序，还可以远程与 Docker_Host 进行交互。</p><p class="ql-align-justify">最常用的 Docker 客户端就是 Docker 命令，我们可以通过 Docker 命令很方便地在 Host 上构建和运行 Docker 容器。</p><p class="ql-align-center"><br></p><div class="pgc-img"><img src="http://p3.pstatp.com/large/pgc-image/1540437483619ea261b99ba" img_width="500" img_height="270" alt="这可能是最为详细的Docker入门吐血总结" inline="0"><p class="pgc-img-caption"></p></div><p class="ql-align-center"><br></p><p class="ql-align-justify"><strong>Docker Daemon</strong></p><p class="ql-align-justify">Docker Daemon 是服务器组件，以 Linux 后台服务的方式运行，是 Docker 最核心的后台进程，我们也把它称为守护进程。</p><p class="ql-align-justify">它负责响应来自 Docker Client 的请求，然后将这些请求翻译成系统调用完成容器管理操作。</p><p class="ql-align-justify">该进程会在后台启动一个 API Server ，负责接收由 Docker Client 发送的请求，接收到的请求将通过 Docker Daemon 内部的一个路由分发调度，由具体的函数来执行请求。</p><p class="ql-align-center"><br></p><div class="pgc-img"><img src="http://p9.pstatp.com/large/pgc-image/1540437483705b79fa4c429" img_width="500" img_height="271" alt="这可能是最为详细的Docker入门吐血总结" inline="0"><p class="pgc-img-caption"></p></div><p class="ql-align-center"><br></p><p class="ql-align-justify">我们大致可以将其分为以下三部分：</p><ul><li><strong>Docker Server</strong></li><li><strong>Engine</strong></li><li><strong>Job</strong></li></ul><p class="ql-align-justify">Docker Daemon 的架构如下所示：</p><p class="ql-align-center"><br></p><div class="pgc-img"><img src="http://p1.pstatp.com/large/pgc-image/154043748372362abbe96b9" img_width="500" img_height="368" alt="这可能是最为详细的Docker入门吐血总结" inline="0"><p class="pgc-img-caption"></p></div><p class="ql-align-center"><br></p><p class="ql-align-justify">Docker Daemon 可以认为是通过 Docker Server 模块接受 Docker Client 的请求，并在 Engine 中处理请求，然后根据请求类型，创建出指定的 Job 并运行。</p><p class="ql-align-justify">Docker Daemon 运行在 Docker Host 上，负责创建、运行、监控容器，构建、存储镜像。</p><p class="ql-align-justify">运行过程的作用有以下几种可能：</p><ul><li>向 Docker Registry 获取镜像。</li><li>通过 graphdriver 执行容器镜像的本地化操作。</li><li>通过 networkdriver 执行容器网络环境的配置。</li><li>通过 execdriver 执行容器内部运行的执行工作。</li></ul><p class="ql-align-justify">由于 Docker Daemon 和 Docker Client 的启动都是通过可执行文件 Docker 来完成的，因此两者的启动流程非常相似。</p><p class="ql-align-justify">Docker 可执行文件运行时，运行代码通过不同的命令行 Flag 参数，区分两者，并最终运行两者各自相应的部分。</p><p class="ql-align-justify">启动 Docker Daemon 时，一般可以使用以下命令来完成：</p><pre>docker --daemon = truedocker –d <br>docker –d = true <br></pre><p class="ql-align-justify">再由 Docker 的 main() 函数来解析以上命令的相应 Flag 参数，并最终完成 Docker Daemon 的启动。</p><p>下图可以很直观地看到 Docker Daemon 的启动流程：</p><div class="pgc-img"><img src="http://p1.pstatp.com/large/pgc-image/15404374837235e5f0fe2a4" img_width="500" img_height="602" alt="这可能是最为详细的Docker入门吐血总结" inline="0"><p class="pgc-img-caption"></p></div><p class="ql-align-justify">默认配置下，Docker Daemon 只能响应来自本地 Host 的客户端请求。如果要允许远程客户端请求，需要在配置文件中打开 TCP 监听。</p><p class="ql-align-justify">我们可以照着如下步骤进行配置：</p><p class="ql-align-justify">①编辑配置文件/etc/systemd/system/multi-user.target.wants/docker.service，在环境变量 ExecStart 后面添加 -H tcp://0.0.0.0，允许来自任意 IP 的客户端连接。</p><p class="ql-align-center"><br></p><div class="pgc-img"><img src="http://p3.pstatp.com/large/pgc-image/15404374837212af51bc3b9" img_width="500" img_height="159" alt="这可能是最为详细的Docker入门吐血总结" inline="0"><p class="pgc-img-caption"></p></div><p class="ql-align-center"><br></p><p class="ql-align-justify">②重启 Docker Daemon：</p><pre>systemctl daemon-reload <br>systemctl restart docker.service <br></pre><p class="ql-align-justify">③我们通过以下命令即可实现与远程服务器通信：</p><pre>docker -H 服务器IP地址 info <br></pre><p class="ql-align-justify">-H 是用来指定服务器主机，info 子命令用于查看 Docker 服务器的信息。</p><p class="ql-align-justify"><strong>Docker Image</strong></p><p class="ql-align-justify">Docker 镜像可以看作是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数(如匿名卷、环境变量、用户等)。</p><p class="ql-align-justify">镜像不包含任何动态数据，其内容在构建之后也不会被改变。我们可将 Docker 镜像看成只读模板，通过它可以创建 Docker 容器。</p><p class="ql-align-justify">镜像有多种生成方法：</p><ul><li><strong>从无到有开始创建镜像</strong></li><li><strong>下载并使用别人创建好的现成的镜像</strong></li><li><strong>在现有镜像上创建新的镜像</strong></li></ul><p class="ql-align-justify">我们可以将镜像的内容和创建步骤描述在一个文本文件中，这个文件被称作 Dockerfile ，通过执行 docker build 命令可以构建出 Docker 镜像。</p><p class="ql-align-justify"><strong>Docker Registry</strong></p><p>Docker Registry 是存储 Docker Image 的仓库，它在 Docker 生态环境中的位置如下图所示：</p><p class="ql-align-center"><br></p><div class="pgc-img"><img src="http://p3.pstatp.com/large/pgc-image/1540437483766706e52e4af" img_width="500" img_height="157" alt="这可能是最为详细的Docker入门吐血总结" inline="0"><p class="pgc-img-caption"></p></div><p class="ql-align-center"><br></p><p class="ql-align-justify">运行 docker push、docker pull、docker search 时，实际上是通过 Docker Daemon 与 Docker Registry 通信。</p><p class="ql-align-justify"><strong>Docker Container</strong></p><p class="ql-align-justify">Docker 容器就是 Docker 镜像的运行实例，是真正运行项目程序、消耗系统资源、提供服务的地方。</p><p class="ql-align-justify">Docker Container 提供了系统硬件环境，我们可以使用 Docker Images 这些制作好的系统盘，再加上我们所编写好的项目代码，Run 一下就可以提供服务啦。</p><p class="ql-align-justify"><strong>Docker 组件是如何协作运行容器</strong></p><p class="ql-align-justify">看到这里，我相信各位读者朋友们应该已经对 Docker 基础架构熟悉的差不多了，我们还记得运行的第一个容器吗?</p><p class="ql-align-justify">现在我们再通过 hello-world 这个例子来体会一下 Docker 各个组件是如何协作的。</p><p class="ql-align-justify">容器启动过程如下：</p><ul><li>Docker 客户端执行 docker run 命令。</li><li>Docker Daemon 发现本地没有 hello-world 镜像。</li><li>Daemon 从 Docker Hub 下载镜像。</li><li>下载完成，镜像 hello-world 被保存到本地。</li><li>Docker Daemon 启动容器。</li></ul><p class="ql-align-justify">具体过程可以看如下这幅演示图：</p><p class="ql-align-center"><br></p><div class="pgc-img"><img src="http://p3.pstatp.com/large/pgc-image/15404374837950bb41b5243" img_width="500" img_height="263" alt="这可能是最为详细的Docker入门吐血总结" inline="0"><p class="pgc-img-caption"></p></div><p class="ql-align-center"><br></p><p class="ql-align-justify">我们可以通过 Docker Images 可以查看到 hello-world 已经下载到本地：</p><p class="ql-align-center"><br></p><div class="pgc-img"><img src="http://p3.pstatp.com/large/pgc-image/15404374838229a52253032" img_width="500" img_height="29" alt="这可能是最为详细的Docker入门吐血总结" inline="0"><p class="pgc-img-caption"></p></div><p class="ql-align-center"><br></p><p class="ql-align-justify">我们可以通过 Docker Ps 或者 Docker Container ls 显示正在运行的容器，我们可以看到，hello-world 在输出提示信息以后就会停止运行，容器自动终止，所以我们在查看的时候没有发现有容器在运行。</p><p class="ql-align-center"><br></p><div class="pgc-img"><img src="http://p1.pstatp.com/large/pgc-image/154043748381858997113fc" img_width="500" img_height="16" alt="这可能是最为详细的Docker入门吐血总结" inline="0"><p class="pgc-img-caption"></p></div><p class="ql-align-center"><br></p><p class="ql-align-justify">我们把 Docker 容器的工作流程剖析的十分清楚了，我们大体可以知道 Docker 组件协作运行容器可以分为以下几个过程：</p><ul><li>Docker 客户端执行 docker run 命令。</li><li>Docker Daemon 发现本地没有我们需要的镜像。</li><li>Daemon 从 Docker Hub 下载镜像。</li><li>下载完成后，镜像被保存到本地。</li><li>Docker Daemon 启动容器。</li></ul><p class="ql-align-justify">了解了这些过程以后，我们再来理解这些命令就不会觉得很突兀了，下面我来给大家讲讲 Docker 常用的一些命令操作吧。</p><p class="ql-align-justify"><strong>Docker 常用命令</strong></p><p>我们可以通过 docker -h 去查看命令的详细的帮助文档。在这里我只会讲一些日常我们可能会用的比较多的一些命令。</p><p class="ql-align-center"><br></p><div class="pgc-img"><img src="http://p9.pstatp.com/large/pgc-image/15404374838451e3f53be64" img_width="500" img_height="359" alt="这可能是最为详细的Docker入门吐血总结" inline="0"><p class="pgc-img-caption"></p></div><p class="ql-align-center"><br></p><p class="ql-align-justify">例如，我们需要拉取一个 Docker 镜像，我们可以用如下命令：</p><pre>docker pull image_name <br></pre><p class="ql-align-justify">image_name 为镜像的名称，而如果我们想从 Docker Hub 上去下载某个镜像，我们可以使用以下命令：</p><pre>docker pull centos:latest <br></pre><p class="ql-align-justify">cento：lastest 是镜像的名称，Docker Daemon 发现本地没有我们需要的镜像，会自动去 Docker Hub 上去下载镜像，下载完成后，该镜像被默认保存到 /var/lib/docker 目录下。</p><p class="ql-align-justify">接着我们如果想查看主机下存在多少镜像，我们可以用如下命令：</p><pre>docker images <br></pre><p class="ql-align-justify">我们要想知道当前有哪些容器在运行，我们可以用如下命令：</p><pre>docker ps -a <br></pre><p class="ql-align-justify">-a 是查看当前所有的容器，包括未运行的。我们该如何去对一个容器进行启动，重启和停止呢?</p><p class="ql-align-justify">我们可以用如下命令：</p><pre>docker start container_name/container_id <br>docker restart container_name/container_id <br>docker stop container_name/container_id <br></pre><p class="ql-align-justify">这个时候我们如果想进入到这个容器中，我们可以使用 attach 命令：</p><pre>docker attach container_name/container_id <br></pre><p class="ql-align-justify">那如果我们想运行这个容器中的镜像的话，并且调用镜像里面的 bash ，我们可以使用如下命令：</p><pre>docker run -t -i container_name/container_id /bin/bash <br></pre><p class="ql-align-justify">那如果这个时候，我们想删除指定镜像的话，由于 Image 被某个 Container 引用(拿来运行)，如果不将这个引用的 Container 销毁(删除)，那 Image 肯定是不能被删除。</p><p class="ql-align-justify">我们首先得先去停止这个容器：</p><pre>docker psdocker stop container_name/container_id <br></pre><p class="ql-align-justify">然后我们用如下命令去删除这个容器：</p><pre>docker rm container_name/container_id <br></pre><p class="ql-align-justify">然后这个时候我们再去删除这个镜像：</p><pre>docker rmi image_name <br></pre><p class="ql-align-justify">此时，常用的 Docker 相关的命令就讲到这里为止了，我们在后续的文章中还会反复地提到这些命令。</p><p class="ql-align-justify"><strong>Dockerfile 是什么</strong></p><p class="ql-align-justify">前面我们已经提到了 Docker 的一些基本概念。以 CTF 的角度来看，我们可以去使用 Dockerfile 定义镜像，依赖镜像来运行容器，可以去模拟出一个真实的漏洞场景。</p><p class="ql-align-justify">因此毫无疑问的说， Dockerfile 是镜像和容器的关键，并且 Dockerfile 还可以很轻易的去定义镜像内容，说了这么多，那么 Dockerfile 到底是个什么东西呢?</p><p class="ql-align-justify">Dockerfile 是自动构建 Docker 镜像的配置文件，用户可以使用 Dockerfile 快速创建自定义的镜像。Dockerfile 中的命令非常类似于 Linux 下的 Shell 命令。</p><p class="ql-align-justify">我们可以通过下面这幅图来直观地感受下 Docker 镜像、容器和 Dockerfile 三者之间的关系：</p><p class="ql-align-center"><br></p><div class="pgc-img"><img src="http://p3.pstatp.com/large/pgc-image/1540437483882415022c72b" img_width="500" img_height="280" alt="这可能是最为详细的Docker入门吐血总结" inline="0"><p class="pgc-img-caption"></p></div><p class="ql-align-center"><br></p><p class="ql-align-justify">我们从上图中可以看到，Dockerfile 可以自定义镜像，通过 Docker 命令去运行镜像，从而达到启动容器的目的。Dockerfile 是由一行行命令语句组成，并且支持已 # 开头的注释行。</p><p class="ql-align-justify">一般来说，我们可以将 Dockerfile 分为四个部分：</p><ul><li>基础镜像(父镜像)信息指令 FROM。</li><li>维护者信息指令 MAINTAINER。</li><li>镜像操作指令 RUN 、EVN 、ADD 和 WORKDIR 等。</li><li>容器启动指令 CMD 、ENTRYPOINT 和 USER 等。</li></ul><p class="ql-align-justify">下面是一段简单的 Dockerfile 的例子：</p><pre>FROM python:2.7MAINTAINER Angel_Kitty &lt;angelkitty6698@gmail.com&gt;COPY . /app <br>WORKDIR /app <br>RUN pip install -r requirements.txt <br>EXPOSE 5000ENTRYPOINT ["python"]CMD ["app.py"] <br></pre><p class="ql-align-justify">我们可以分析一下上面这个过程：</p><ul><li>从 Docker Hub 上 Pull 下 Python 2.7 的基础镜像。</li><li>显示维护者的信息。</li><li>Copy 当前目录到容器中的 /App 目录下 复制本地主机的 ( Dockerfile 所在目录的相对路径)到容器里 。</li><li>指定工作路径为 /App。</li><li>安装依赖包。</li><li>暴露 5000 端口。</li><li>启动 App。</li></ul><p class="ql-align-justify">这个例子是启动一个 Python Flask App 的 Dockerfile ( Flask 是 Python 的一个轻量的 Web 框架)，相信大家从这个例子中能够稍微理解了 Dockfile 的组成以及指令的编写过程。</p><p class="ql-align-justify"><strong>Dockerfile 常用的指令</strong></p><p class="ql-align-justify">根据上面的例子，我们已经差不多知道了 Dockerfile 的组成以及指令的编写过程，我们再来理解一下这些常用命令就会得心应手了。</p><p class="ql-align-justify">由于 Dockerfile 中所有的命令都是以下格式：INSTRUCTION argument ，指令(INSTRUCTION)不分大小写，但是推荐大写和 SQL 语句是不是很相似呢?下面我们正式来讲解一下这些指令集吧。</p><p class="ql-align-justify"><strong>FROM</strong></p><p class="ql-align-justify">FROM 是用于指定基础的 images ，一般格式为 FROM or FORM :。</p><p class="ql-align-justify">所有的 Dockerfile 都应该以 FROM 开头，FROM 命令指明 Dockerfile 所创建的镜像文件以什么镜像为基础，FROM 以后的所有指令都会在 FROM 的基础上进行创建镜像。</p><p class="ql-align-justify">可以在同一个 Dockerfile 中多次使用 FROM 命令用于创建多个镜像。比如我们要指定 Python 2.7 的基础镜像，我们可以像如下写法一样：</p><pre>FROM python:2.7 <br></pre><p class="ql-align-justify"><strong>MAINTAINER</strong></p><p class="ql-align-justify">MAINTAINER 是用于指定镜像创建者和联系方式，一般格式为 MAINTAINER 。</p><p class="ql-align-justify">这里我设置成我的 ID 和邮箱：</p><pre>MAINTAINER Angel_Kitty &lt;angelkitty6698@gmail.com&gt; <br></pre><p class="ql-align-justify"><strong>COPY</strong></p><p class="ql-align-justify">COPY 是用于复制本地主机的 (为 Dockerfile 所在目录的相对路径)到容器中的 。</p><p class="ql-align-justify">当使用本地目录为源目录时，推荐使用 COPY 。一般格式为 COPY 。</p><p class="ql-align-justify">例如我们要拷贝当前目录到容器中的 /app 目录下，我们可以这样操作：</p><pre>COPY . /app <br></pre><p class="ql-align-justify"><strong>WORKDIR</strong></p><p class="ql-align-justify">WORKDIR 用于配合 RUN，CMD，ENTRYPOINT 命令设置当前工作路径。</p><p class="ql-align-justify">可以设置多次，如果是相对路径，则相对前一个 WORKDIR 命令。默认路径为/。一般格式为 WORKDIR /path/to/work/dir。</p><p class="ql-align-justify">例如我们设置 /app 路径，我们可以进行如下操作：</p><pre>WORKDIR /app <br></pre><p class="ql-align-justify"><strong>RUN</strong></p><p class="ql-align-justify">RUN 用于容器内部执行命令。每个 RUN 命令相当于在原有的镜像基础上添加了一个改动层，原有的镜像不会有变化。一般格式为 RUN 。</p><p class="ql-align-justify">例如我们要安装 Python 依赖包，我们做法如下：</p><pre>RUN pip install -r requirements.txt <br></pre><p class="ql-align-justify"><strong>EXPOSE</strong></p><p class="ql-align-justify">EXPOSE 命令用来指定对外开放的端口。一般格式为 EXPOSE [ ...]。</p><p class="ql-align-justify">例如上面那个例子，开放5000端口：</p><pre>EXPOSE 5000 <br></pre><p class="ql-align-justify"><strong>ENTRYPOINT</strong></p><p class="ql-align-justify">ENTRYPOINT 可以让你的容器表现得像一个可执行程序一样。一个 Dockerfile 中只能有一个 ENTRYPOINT，如果有多个，则最后一个生效。</p><p class="ql-align-justify">ENTRYPOINT 命令也有两种格式：</p><ul><li>ENTRYPOINT ["executable", "param1", "param2"] ：推荐使用的 Exec 形式。</li><li>ENTRYPOINT command param1 param2 ：Shell 形式。</li></ul><p class="ql-align-justify">例如下面这个，我们要将 Python 镜像变成可执行的程序，我们可以这样去做：</p><pre>ENTRYPOINT ["python"] <br></pre><p class="ql-align-justify"><strong>CMD</strong></p><p class="ql-align-justify">CMD 命令用于启动容器时默认执行的命令，CMD 命令可以包含可执行文件，也可以不包含可执行文件。</p><p class="ql-align-justify">不包含可执行文件的情况下就要用 ENTRYPOINT 指定一个，然后 CMD 命令的参数就会作为 ENTRYPOINT 的参数。</p><p class="ql-align-justify">CMD 命令有三种格式：</p><ul><li>CMD ["executable","param1","param2"]：推荐使用的 exec 形式。</li><li>CMD ["param1","param2"]：无可执行程序形式。</li><li>CMD command param1 param2：Shell 形式。</li></ul><p class="ql-align-justify">一个 Dockerfile 中只能有一个 CMD，如果有多个，则最后一个生效。而 CMD 的 Shell 形式默认调用 /bin/sh -c 执行命令。</p><p class="ql-align-justify">CMD 命令会被 Docker 命令行传入的参数覆盖：docker run busybox /bin/echo Hello Docker 会把 CMD 里的命令覆盖。</p><p class="ql-align-justify">例如我们要启动 /app ，我们可以用如下命令实现：</p><pre>CMD ["app.py"] <br></pre><p class="ql-align-justify">当然还有一些其他的命令，我们在用到的时候再去一一讲解一下。</p><p class="ql-align-justify"><strong>构建 Dockerfile</strong></p><p class="ql-align-justify">我们大体已经把 Dockerfile 的写法讲述完毕，我们可以自己动手写一个例子：</p><pre>mkdir static_web <br>cd static_web <br>touch Dockerfile <br></pre><p class="ql-align-justify">然后 vi Dockerfile 开始编辑该文件，输入 i 开始编辑。以下是我们构建的 Dockerfile 内容：</p><pre>FROM nginx <br>MAINTAINER Angel_Kitty &lt;angelkitty6698@gmail.com&gt; <br>RUN echo '&lt;h1&gt;Hello, Docker!&lt;/h1&gt;' &gt; /usr/share/nginx/html/index.html <br></pre><p class="ql-align-justify">编辑完后按 esc 退出编辑，然后 ：wq写入，退出。</p><p class="ql-align-justify">我们在 Dockerfile 文件所在目录执行：</p><pre>docker build -t angelkitty/nginx_web:v1 . <br></pre><p class="ql-align-justify">我们解释一下：</p><ul><li>-t 是为新镜像设置仓库和名称</li><li>angelkitty 为仓库名</li><li>nginx_web 为镜像名</li><li>：v1 为标签(不添加为默认 latest )</li></ul><p class="ql-align-justify">我们构建完成之后，使用 Docker Images 命令查看所有镜像，如果存在 REPOSITORY 为 Nginx 和 TAG 是 v1 的信息，就表示构建成功。</p><p class="ql-align-center"><br></p><div class="pgc-img"><img src="http://p1.pstatp.com/large/pgc-image/1540437483933ff478b60d5" img_width="500" img_height="276" alt="这可能是最为详细的Docker入门吐血总结" inline="0"><p class="pgc-img-caption"></p></div><p class="ql-align-center"><br></p><p class="ql-align-justify">接下来使用 docker run 命令来启动容器：</p><pre>docker run --name nginx_web -d -p 8080:80 angelkitty/nginx_web:v1 <br></pre><p class="ql-align-justify">这条命令会用 Nginx 镜像启动一个容器，命名为 nginx_web ，并且映射了 8080 端口。</p><p class="ql-align-justify">这样我们可以用浏览器去访问这个 Nginx 服务器：http://localhost:8080/ 或者 http://本机的 IP 地址：8080/，页面返回信息：</p><p class="ql-align-center"><br></p><div class="pgc-img"><img src="http://p9.pstatp.com/large/pgc-image/15404374839230f36285646" img_width="500" img_height="122" alt="这可能是最为详细的Docker入门吐血总结" inline="0"><p class="pgc-img-caption"></p></div><p class="ql-align-center"><br></p></div>]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[如何高逼格的给同事做 Elasticsearch 技术分享]]></title>
        <id>https://www.plbear.com/post/how-to-get-started-with-elasticsearch-tutorial</id>
        <link href="https://www.plbear.com/post/how-to-get-started-with-elasticsearch-tutorial">
        </link>
        <updated>2019-07-22T14:35:19.000Z</updated>
        <content type="html"><![CDATA[<div><p>如果你有机会在公司内部做一次Elasticsearch 技术分享，如何才能讲的逼格高，又接地气，那么建议从以下几个方面展开，大家有好的想法，也欢迎文章留言交流。</p><h1>1、可视化展示ELK效果</h1><div class="pgc-img"><img src="http://p3.pstatp.com/large/pgc-image/e6f0b99ab0204c2f89398a825576ea86" img_width="1080" img_height="592" alt="如何高逼格的给同事做 Elasticsearch 技术分享" inline="0"><p class="pgc-img-caption"></p></div><p>如果条件允许，demo的内容是：通过logstash 同步日志或数据库（oracle、mysql）表的数据到 Elasticsearch，然后通过kibana进行可视化。</p><p>1、通过Canvas对数据进行可视化布局与展现，可以实现非常酷炫的大屏展示效果。2、展示实时数据的数据量。3、展示你定的几个维度的数据信息。</p><p>这么切入的目的：很直观，很明显，很接地气。用到ELK技术栈的内容，有带动性，让参与的同事不犯困且很容易让大家对它产生兴趣。</p><h1>2、 Elk stack大家族简介</h1><div class="pgc-img"><img src="http://p1.pstatp.com/large/pgc-image/be95b5a3cb294445bac60559329a2d8f" img_width="1024" img_height="422" alt="如何高逼格的给同事做 Elasticsearch 技术分享" inline="0"><p class="pgc-img-caption"></p></div><p>考虑到不同受众关注点不同。结合业务的数据的特点，从输入、中间处理、存储&amp;检索、分析等全数据流环节展开。</p><p>2.1 输入</p><p>Elastic 支持的输入包含但不限于：</p><p>1、日志类数据：类log4j.log，apache log等，可借助 beats或logstash同步</p><p>2、关系型数据库：mysql oracle pgsql等</p><p>3、非关系型数据库:mongodb redis等</p><p>4、实时数据流：flink spark kafka hdfs等</p><p>5、大数据：hadoop hdfs等</p><p>此处的不同数据的导入，Lostash有丰富的input/output插件，支持N多不同数据源接入，估计同事也会眼前一亮。</p><p>2.2 中间处理ETL</p><p>基础数据很可能是异构的数据，中间的ETL非常重要。logstash filter、elasticsearch ingest 都具备ETL功能。</p><p>2.3 存储&amp;检索</p><p>基于合理的数据建模，在Elastic落地存储，Elastic提供全文检索、数据聚合等。</p><p>2.4 分析</p><p>强调一下，kibana的可视化和监控功能。</p><p>2.5 ELKB认知</p><p>Elastic Stack数据平台由Logstash、Beats、ElasticSearch和Kibana四大核心产品组成，在数据摄取、存储计算分析及数据可视化方面有着无可比拟的优势。</p><p>1、E = Elasticsearch，在存储、计算和分析方面，ElasticSearch允许执行和合并多种类型的搜索，解决不断涌现的各种用例，并具有极高的可用性及容错性，充分保障集群安全。</p><p>2、L = Logstash, Logstash 是开源的服务器端数据处理管道，可同时从多个来源采集、转换数据，并将数据发送到存储库中。</p><p>3、K = Kibana，Kibana作为用户界面的核心，集成了丰富的可视化工具、界面交互开发工具和管理工具，帮助开发人员将数据轻松分享给任何人，甚至还能通过机器学习来监测数据中的隐藏异常并追溯其来源。</p><p>4、B = Beats，Beats作为轻量级的数据搬运工，集合了多种单一用途数据采集器，将数据发送给Logstash或ElasticSearch，其可扩展的框架及丰富的预置采集器将使工作事半功倍。</p><p>以上，主要从大而全的维度，讲解ELK，给大家带来全景认知。</p><p>以这四大核心产品为基础构建的Elastic数据平台实现了数据实时性、相关性及扩展性的完美结合，不仅可以处理各种数据，还能深入挖掘数据的内在关联并迅速呈现，彻底解决企业的大数据实时处理难题。</p><h1>3、 Elasticsearch 是什么？</h1><p>展示的过程中：可以通过kibana的dsl进行展开的讲解。注意例子：可以提前准备好，规划好时间，不用现场敲代码。</p><p>此时可以借助head插件或者kibama-dev讲解。</p><p>3.1 Elasticsearch的组成</p><p>如果是集群部署的更好。讲解内容包括：</p><ul><li class="ql-align-justify">集群、</li><li class="ql-align-justify">索引、</li><li class="ql-align-justify">分片、</li><li class="ql-align-justify">副本、</li><li class="ql-align-justify">分段、</li><li class="ql-align-justify">倒排索引。</li><li class="ql-align-justify">ES的底层是lucene等。</li></ul><div class="pgc-img"><img src="http://p1.pstatp.com/large/pgc-image/423dfe02f753443a8ecba9e0f0a774f1" img_width="755" img_height="459" alt="如何高逼格的给同事做 Elasticsearch 技术分享" inline="0"><p class="pgc-img-caption"></p></div><p>3.2 Elasticsearch分布式可扩展的特性</p><p>强调Elasticsearch可以支持PB级别甚至更高级别数据量的存储。</p><p>3.3 强调Elasticsearch特点</p><p>1、简单的restful api，天生的兼容多语言开发。2、分布式的实时文件存储，每个字段都被索引且可用于搜索。3、分布式的实时分析搜索引擎，海量数据下近实时秒级响应。4、易扩展，处理PB级结构化或非结构化数据。</p><h1>4、 Elasticsearch 能做什么？</h1><p>4.1 全文检索等</p><p>其实也可以类比一下mysql，强调一下：关系型数据库一些检索是做不到的。对比的目的：因为大家都熟悉关系型数据库，这样能够加深理解。</p><p>也可以类比下Google，百度等传统的搜索引擎。告诉同事，其实他们可以做的功能我们都可以做。比如：全文检索，高亮，分页，统计聚合，高级检索等。</p><p>检索的分类：</p><p>1、精确匹配。2、模糊检索。3、正则检索。4、强调全文检索。强调他的快。基于倒排索引实现。5、等等。</p><p>检索类型可以画一个脑图。其实可以，举个例子。演示一下最好。</p><p>4.2 聚合分析</p><p>这里也可以举一下例子。比如:对比一下mycle的group by,limit等功能点讲解。聚合的分类很多，可以抽几个进行讲解。</p><p>4.3 应用场景</p><p>1、记录和日志分析</p><p>2、采集和组合公共数据</p><p>3、全文搜索及个性化推荐</p><p>4、事件数据和指标</p><p>5、数据可视化</p><h1>5、Elasticsearch 极易上手且性能牛逼</h1><p>主流的Java、python、ruby等。C++等也有个人开源维护API。</p><p>可以借助他山之石，把其他公司的应用场景、对应的硬件资源、写入、查询、QPS等性能指标展示出来，凸显牛逼功能和性能。</p><div class="pgc-img"><img src="http://p3.pstatp.com/large/pgc-image/d31ef223121a415188541e227f4de895" img_width="666" img_height="281" alt="如何高逼格的给同事做 Elasticsearch 技术分享" inline="0"><p class="pgc-img-caption"></p></div><h1>6、Elastic 前景光明</h1><p>Elasticsearch在DBRanking 数据库排行榜搜索引擎部分近几年一直处于第一名的领先优势。</p><div class="pgc-img"><img src="http://p9.pstatp.com/large/pgc-image/b41ccbaa0bd14d7d8e8b5141c22fe5be" img_width="913" img_height="468" alt="如何高逼格的给同事做 Elasticsearch 技术分享" inline="0"><p class="pgc-img-caption"></p></div><p>基于Elastic的分布式、可扩展性、良好的性能，BAT、滴滴、美团、小米、华为、携程、360、有赞等几乎所有的主流互联网公司甚至婚庆网站的搜索引擎已经都已经转成ES了。</p><p>那么咱们公司还在犹豫什么呢？</p><h1>7、Elastic技术社区非常活跃</h1><p>这里主要强调，出了问题也不用怕，一个人搞不定，还有国外、国内官方论坛、社区，基本很短时间都能解决问题。</p><p>交流的高效性、问题解决的速度、github迭代更新的速度。以及最近的版本更新的速度:比如7.0的发布，7.0的新特性。大家也会对新的特性充满期待。速度提升快。</p><p>估计讲完这些大家都会跃跃欲试了。</p><h1>8、Elasticsearch 相对薄弱的环节</h1><p>有所为，有所不为。</p><p>8.1 多表关联</p><p>不能简单认为，将mysql同步到Elasticsearch就能解决问题了。</p><p>我们除了看到基于倒排索引Elasticsearch的全文检索的强大，也要看到Elasticsearch对于关系型数据库多表关联的支持相对薄弱，nested类型、Join类型的多表关联操作大数据场景下都会有性能问题。</p><p>8.2 深度分页</p><p>从性能角度考虑，Elasticsearch默认支持10000条数据的返回，除非修改maxresultwindow参数。</p><p>也就是会出现越往后翻页越慢的情况。这点，补救方案：scroll+scroll_after实现。</p><p>但是，更长远角度，建议：参考Google、百度的深度分页实现。</p><p>8.3 实时性</p><p>Elasticsearch是近实时的系统，不是准实时。受限于：refresh_inteval设置，有最快1s延时。</p><p>准实时要求高的场景，建议选型注意。</p><h1>9 小结</h1><p>ELK远不止文章中提到的这些内容，可以说，以上列举的只是<strong>冰山一角</strong>的点，N多底层原理（索引分片原理、写入原理、检索原理、倒排索引原理、高可靠性原理、大数据实战场景等）都没有提及或展开。</p></div>]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[架构成长之路：分布式秒杀系统之如何防止单个用户重复秒杀下单？]]></title>
        <id>https://www.plbear.com/post/jia-gou-cheng-chang-zhi-lu-fen-bu-shi-miao-sha-xi-tong-zhi-ru-he-fang-zhi-dan-ge-yong-hu-chong-fu-miao-sha-xia-dan</id>
        <link href="https://www.plbear.com/post/jia-gou-cheng-chang-zhi-lu-fen-bu-shi-miao-sha-xi-tong-zhi-ru-he-fang-zhi-dan-ge-yong-hu-chong-fu-miao-sha-xia-dan">
        </link>
        <updated>2019-07-20T17:23:25.000Z</updated>
        <content type="html"><![CDATA[<div class="article-content"><div><p>电子交易的一个很基本的问题，就是避免用户下重复订单。用户明明想买一次，结果一看下了两个单。如果没有及时发现，就会带来额外的物流成本和扯皮。对商家的信誉也不好看。</p><p>从技术上看，这是一个分布式一致性问题；但实际上，技术无法100%解决这类问题，得结合多种手段综合处理。这里就来说道说道。</p><h1>为啥会下重了呢？</h1><p><strong>原因1：客户端bug</strong></p><p>比如下单的按键在点按之后，在没有收到服务器请求之前，按键的状态没有设为<strong>已禁用</strong>状态，还可以被按。又或者，在触摸屏下，用户手指的点按可能被手机操作系统识别为多次点击。</p><p>嗯，谁能保证客户端不偶尔出个什么bug 呢。</p><p><strong>原因2: 超时</strong></p><p>用户的设备与服务器之间可能是不稳定的网路。这样一个下单请求过去，返回不一定回得来。超时最大的问题是: 从用户的角度，他无法确定下单的请求是还没到服务器，还是已经到了服务器但是返回丢失了。——<strong>用户无法区分到底这个单下了还是没下</strong>。</p><p>这样在等待一个超时后，UI可能会提示用户下单超时，请重复再试。</p><div class="pgc-img"><img src="http://p1.pstatp.com/large/pgc-image/a3c09c7618b447d1b0a265c1620bd23c" img_width="1000" img_height="244" alt="架构成长之路：分布式秒杀系统之如何防止单个用户重复秒杀下单？" inline="0"><p class="pgc-img-caption"></p></div><p><strong>原因3: 用户的App闪退/人工强退，之后重新打开重新下单</strong></p><p>也许可以使用一些技术手段避免用户下重单，但是心急的用户可能会重启流程/重启App/重启手机。在这种强制的手段下，任何技术手段都会失效——用户压根就不让你的技术执行，你怎么玩？</p><p><strong>在这些条件下，如何避免用户多下了一笔订单呢？</strong></p><h1>用幂等防止重复订单</h1><p>在技术方面，这是一个分布式一致性的问题，即客户端和服务器端对某个订单是否成功/失败达成一致。防止重单的关键是<strong>使用一个由客户端生成的，可用于避免重复的key</strong>，俗称<strong>dedup key</strong>（deduplicate key之意）。这个key可以用任意可以保证全局唯一性的方式生成，比如uuid。客户端和服务器需要使用这个dedup key作为串联条件，一起解决去重问题。</p><h1>客户端的流程</h1><p>客户端需要实现这样一个下单界面。用户点击【确认下单】时，应该产生一个独一无二的dedup key，连定订单数据发送给服务器端。在服务器返回之前，该界面应该一直等待，直到服务器响应成功/失败或者超时发生（比如15秒后，收不到服务器响应）。如果超时发生，应该向用户提示是否重试下单或者退出该界面。当用户点击【重试】时，应该用刚刚生成的dedup key来再次发送下单请求——如果用户一直不退出这个流程，每次用户点击重试，都应该用这个dedup key来重试下单，直到服务器正常返回，或者用户放弃返回。</p><div class="pgc-img"><img src="http://p1.pstatp.com/large/pgc-image/3659880202454777a9d7a649a524456f" img_width="1000" img_height="528" alt="架构成长之路：分布式秒杀系统之如何防止单个用户重复秒杀下单？" inline="0"><p class="pgc-img-caption">下单的客户端流程</p></div><h1>后端数据表设计</h1><p>后端在订单数据表中，需要增加dedup_key这列，并设置<strong>唯一约束</strong>。</p><pre>create table order(<br> # ...<br> dedup_key varchar(60) not null comment 'key to pretend order duplication',<br> # ...<br> unique uniq_dedup_key(dedup_key)<br>);<br></pre><h1>下单的实现</h1><p>在实现下单逻辑时，基于该dedup_key实现一个"create-or-get"语义的下单接口——简单说就是</p><blockquote><p>如果带有指定dedup_key的订单已经存在，则直接返回；否则，用该dedup_key下单。</p></blockquote><p>用伪代码表示大概是：</p><pre>@Transactional<br>Order createOrder(Integer userId, String prodCode, Decimal amount, String dedupKey) {<br> try {<br> String orderId = createOrder(userId, prodCode, amount, deupKey); // insert a new order<br> Order order = getOrderById(orderId); // read order from db<br> order.setDuplicated(false);<br> return order;<br> } catch(UniqueKeyViolationException e) {<br> // if duplicated order has existed<br> Order order = getOrderByDedupKey(dedupKey);<br> order.setDuplicated(true);<br> return order;<br> } catch (Exception e) {<br> // hanlde other errors and rollback transaction ...<br> }<br>}<br></pre><p>这时，这段下单代码总是能返回一个订单（除非发生一些DB挂了之类的错误），要么是新创建的，要么就是一个已经存在的单。注意，<strong>最好在订单里增加一个属性（比如例子中用“duplicated”）来表示这个订单是这次新生成的，还是因为幂等而直接返回的</strong>。这样前端可以有针对性的对这两种情况提示不同的文案。</p><h1>技术搞定幂等就足够了吗？</h1><p>上面的流程没有考虑一种情况，就是用户中途强制退出客户端，或者直接点击【返回】回到产品页，重新走下单流程。这个时候客户端就无法判断用户到底是想重新下单，还是想第二次下单。此时，可以从产品设计上考虑一下。</p><p>比如，在客户端缓存一个表，记录所有没有确认结果的订单。</p><p> 产品代码 产品数量 金额 dedup key 未确认订单1 AAA 1 1000 xxx-yyy-zzz 未确认订单2 BBB 2 500.00 Aaa-bbb-ccc ... 通过这个表，我们可以<strong>猜</strong>一下用户的意图。比如，如果用户重新提交了一笔订单，其产品代码、金额与表中记录的某条完全一致，就可以提示一下用户:</p><div class="pgc-img"><img src="http://p1.pstatp.com/large/pgc-image/f1df5062d20e4def95ab2fc7d456d4d4" img_width="676" img_height="274" alt="架构成长之路：分布式秒杀系统之如何防止单个用户重复秒杀下单？" inline="0"><p class="pgc-img-caption">提示一下用户是不是下重了</p></div><p>如果用户想重试，可以继续用表中对应记录的dedup key重新发起下单。</p><p>这样不是绝对准确的，仅仅是尽量的减少用户误操作的可能性。当然，在产品设计上可以能出于用户交互简化，不一定真的会这样做。这就需要其他机制来配合，比如“通知”。</p><h1>通知</h1><p>一旦服务器下单成功，可以通过某种通知机制（如APNS、Websocket）主动将订单推送至客户端，强行让客户端重新拉取最新的订单信息，并配合“未确认订单”表，以通知Badge/弹框等方式提示用户刚刚一笔状态未知的订单成功/失败了。</p><p>另外一种手段就是，服务器端实时扫描用户的下单数据，一旦发现可能的重单，就立刻通知客服<strong>主动</strong>联系用户，及时处理问题。</p><h1>如果还拦不住……</h1><p>经过层层阻拦，可能还是会有用户误操作，直到收到两份商品才发现下重了。此时就得依靠运营/客服的支持了。提供用户申诉的手段，让用户提出哪些订单是重复的，并且由销售系统店家、商品提供者和买家三方共同根据用户操作的记录来协商如何处理。我们需要让技术帮助让这种人工处理的几率尽量小。因为每次处理都会耗费较大的人工成本，和一些运营费用（比如赔款、小礼品等等）。</p><h1>这么麻烦，有必要吗？</h1><p>这要分业务场景，对于很多电商来讲可能不是必要的。因为从用户下单到订单被审核处理进入到发货阶段需要一定的时间（可能是半小时～1小时），并且一定是支付成功后才会开始进行下一步流程。在这个时间段，用户大概率能从网络错误中恢复过来，自行区分是否下重了。配合客服主动提示，会极大的降低出问题的概率。</p><p>但是对于理财服务来说，这种去重就非常必要了。因为</p><ul><li><strong>“下单+支付”</strong>。用户购买理财往往是“下单+支付”一起执行，不可以单独下单/单独支付</li><li><strong>用户的入金可能很大</strong>。例如数万，数十万</li><li><strong>准确性丢失</strong>。如果一旦下重了，有可能影响用户的投资资金配置的准确性。</li><li><strong>撤销难</strong>。部分理财产品存在下单不可撤销的问题；或者即便撤销，资金也无法立刻回款。等到回款，可能这个购入机会就错过去了。例如对于基金交易，错过1个交易日，价格就会发生变动。</li></ul><p>基于这些特性，在理财产品中，就要竭尽全力的去重。</p><h1>结论</h1><p>以上所讲是处理重复订单问题的一般方法。你可以注意到，无论多么好的技术，也不可能100%的拦截所有的可能性，必须依靠<strong>技术+产品设计+运营支持</strong>的综合手段才能解决这类问题。</p><p>另外，本文还没涉及到关于订单支付（支付也可能重复哦）带来的进一步的复杂性，也没有讨论在高并发情况下的性能优化，仅仅讨论下单本身的问题。所以可以想象一下现实中的交易业务比这里的说的要复杂得多。</p><p>本文介绍的原理也不仅仅适用于防止下重复订单，而是可以应用到任何<strong>需要“创建一个不应该重复资源”</strong>的场景，比如“向用户发一条通知”，“触发一次不能重复的批处理任务！</p></div></div>]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[在西方的程序员眼里，东方的程序员是什么样的？]]></title>
        <id>https://www.plbear.com/post/zai-xi-fang-de-cheng-xu-yuan-yan-li-dong-fang-de-cheng-xu-yuan-shi-shi-me-yang-de</id>
        <link href="https://www.plbear.com/post/zai-xi-fang-de-cheng-xu-yuan-yan-li-dong-fang-de-cheng-xu-yuan-shi-shi-me-yang-de">
        </link>
        <updated>2019-07-20T15:52:01.000Z</updated>
        <content type="html"><![CDATA[<div class="article-content"><div><p>最近，在国外著名的stackexchange网站上出现了一个有趣的问题，有人问：西方的程序员眼里，东方的程序员是什么样的？他描述道：</p><p>世界的东方（印度/中国/菲律宾）是西方（美国/欧洲）的主要软件外包服务提供者。</p><p>你是否有过与这种离岸外包团队合作的经历？如果有，感觉如何？</p><p>你对这些来自东方的程序员有没有一些总结性的看法和观点(比如：他们是否合作，是否能按时提交代码，写出的程序是否有质量？)。依据是什么？</p><p>读者的回复很踊跃，其中一个被顶的最高的回答是关于印度人的，回答中他说一个印度分包商给他们开发了一个组件，他认为这 是他接触过的最恐怖的程序，里面最大的一个文件体积超过600KB，大概有3万多行。他向上天乞求希望自己永远不需要去维护这样的代码。这位答复者说他在 印度生活了3个月，发现东方人和西方人在文化上的差异很大，印度人很勤奋，但常常却不能把事情做对。印度人里有个根深蒂固的文化，就是从不说no，他说即 使你到副食品商店里要求买一条毯子，店主也会说“是，先生，稍等一会”，然后派一个小孩到外面商店把东西买回来。这虽然在生意上是好的做法，但未必适用于 做软件开发。</p><p>另外一个回复是关于俄国人的，同样，他觉得这些俄国人写的代码顶多当作原型来使用，最终都会被丢掉，不能用。</p><p>我找了很久，终于在帖子的最底部发现一个关于中国程序员的回复，不过内容非常的有趣：</p><p>到现在，我在中国已经待了2年多一点时间了(我是个加拿大人)，跟中国的开发人员一起共事你会感到非常的奇特。我敢说上面这些关于东方的程序员的总结都是正确的，至少对于中国人是这样的。我遇到的/一起共事的大多数开发人员基本属于这种情况：</p><p><strong>缺少上进心和创造性。</strong>这里我并不想说他们很差劲或愚蠢。也许更可能是一种文化。在历史上他们就有一种官本位和 崇尚权威的传统。于是他们对来自“上面”的糟糕的设计从不提出疑议。同样，他们更多的是关注技术技巧，而忽略业务领域知识。我费力九牛二虎之力教他们模式 和各种抽象概念，直到他们能应用这些东西到他们手头的任务中。然而，过不了多久，就像是决堤的洪水，他们竟然肆无忌惮的挑战权威，至少在技术层面上是这样 的，我可不想弄得签证被撤销。;-)</p><p><strong>磨擦</strong>前面这个问题说过，但我要强调一下。这也许是最重要的一个问题，是产生中国开发人员跟这里的海外同事(这里是加拿大人)共事时产生紧张关系的原因。通常， 我在这里共事的西方人会特意的夸大跟东方人共事时东方人的一些不好的方面。我这些加拿大同事对人友好但在代码审查时极其的苛刻。如果发现这些中国程序员一 个小失误或没有使用好的编写方法，他们就是发脾气、大呼小叫。但当他们自己被礼貌的要求也按照这种要求完成他们自己的任务时，他们也会发脾气、大呼小叫。</p><p><strong>牺牲</strong>中国人并不以介意使用蹩脚的二手器械。我坐坏了三把椅子后才终于要了一把稍微舒服一点的椅子。可是当我坐上这把较好的椅子后，突然感觉不是很好，因为看到 这些中国人仍然坐在好像是中世纪那么原始的椅子上。然而，等我访问了这家公司的总部后，我发现这里的程序员的一张桌子就有我们4～6个人的团队的占地面积 那么大，更别提他们的椅子了！</p><p>在起初，他们编写的程序并不是很好。这当然是文化上产生的裂痕，但这也是开始时糟糕的系统设计产生的很陡的学习曲线造成的。但你们知道吗，两年之后，这个系统中一些最优秀的模块都是出自中国公司。于是这就更加明显的导致了双方程序员的磨擦加剧…</p><p>坦白的说，这几年走过来不容易，以个人经验判断事情的趋势，我认为对这个问题的看法是正确的。</p><p>做为一个中国人，对于西方人对我们的看法和观点，我觉得不需要去急着找他们的论点漏洞进行反驳。你可感到到他们对东方人的不满是一种普遍弥漫的气氛，俗话说，苍蝇不叮无缝的蛋，我们应该还是先从自身找问题，有则改之，无则加勉。</p><div class="pgc-img"><img src="http://p1.pstatp.com/large/pgc-image/40ba7b75a14a4b6fab8dd92c0c239297" img_width="773" img_height="395" alt="在西方的程序员眼里，东方的程序员是什么样的？" inline="0"></div></div></div>]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Gamification]]></title>
        <id>https://www.plbear.com/post/roleplayinglife</id>
        <link href="https://www.plbear.com/post/roleplayinglife">
        </link>
        <updated>2019-07-20T15:10:21.000Z</updated>
        <content type="html"><![CDATA[<iframe width="100%" height="600px"  frameborder="0" scrolling="no" src="https://liveshare.huya.com/iframe/plbear"></iframe>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hello World]]></title>
        <id>https://www.plbear.com/post/about</id>
        <link href="https://www.plbear.com/post/about">
        </link>
        <updated>2019-07-20T14:53:35.000Z</updated>
        <summary type="html"><![CDATA[<p>👏  欢迎来到 <strong>绿林好汉</strong> ！<br>
✍️  <strong>绿林好汉</strong> 互联网行业连续创业者，全栈工程师。分享自己的思考过程和工作实践！踏平行业入门之槛。这里记录生活、心情、知识、笔记、创意... ...</p>
]]></summary>
        <content type="html"><![CDATA[<p>👏  欢迎来到 <strong>绿林好汉</strong> ！<br>
✍️  <strong>绿林好汉</strong> 互联网行业连续创业者，全栈工程师。分享自己的思考过程和工作实践！踏平行业入门之槛。这里记录生活、心情、知识、笔记、创意... ...</p>
<!-- more -->
<p><a href="https://github.com/iyabao">Github</a></p>
<h2 id="food-and-freedom">Food And Freedom👇</h2>
<p>📝  学习不分春夏秋冬，贵在坚持；奋斗可分鼠雀鲲鹏，人生贵搏</p>
<p>🌉  山不过来，我就过去</p>
<p>🏷️  险夷原不滞胸中,何异浮云过太空？夜静海涛三万里,月明飞锡下天风。</p>
<p>📋  贵有恒，何必三更起五更睡；最无益，只怕一日暴十寒。</p>
<p>💻  努力，是为了将运气成分降到最低。</p>
<p>🌎  在宇宙的历史长河中，我们渺小到绝望。但这不应该是我们该操心的事。我们应该为未来未知的风险做好充足的准备。</p>
<p>💬  Blessed be the Lord my strength,which teaches my hands to war and my fingers to fight.My goodness and my fortress.My high tower and deliverer.My shield and He in whom I trust！</p>
<p>🌁  Talk is cheap show me the code！</p>
<p>🖥  If a new user has a bad time, it's a bug. Just Keep IT Simple &amp; Stupid</p>
<p>🌱 To be, or not to be, that is a question. Do or do not, there is no try.</p>
<p>皆さんが好きなことを仕事にできますように</p>
<p>Role Playing Life.</p>
<p>😘 Enjoy~</p>
]]></content>
    </entry>
</feed>